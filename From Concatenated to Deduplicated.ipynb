{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dacb87c7-c90f-4f3e-943d-fe8bc97e2b0b",
   "metadata": {},
   "source": [
    "## III Concatenation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e54ad9e8-7260-4b12-a130-9ebdf5eae21d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The common files list of documents.dat is :  {'titlekeywords.dat', 'references.dat', 'authorskeywords.dat', 'authors.dat', 'addresses.dat', 'journalkeywords.dat', 'subjects2.dat', 'institutions.dat', 'subjects.dat', 'articles.dat', 'countries.dat', 'authorsinst.dat'}\n",
      "Etape terminée\n"
     ]
    }
   ],
   "source": [
    "# Local imports\n",
    "import BiblioMeter_Utils as bmu\n",
    "\n",
    "# 3rd party library imports\n",
    "import pandas as pd\n",
    "\n",
    "# Allows us to get a list of the documents.dat that will be concatenated\n",
    "list_files = bmu.common_files()\n",
    "\n",
    "# Allows us to get the number by which we need to increment the Pub_id so they can\n",
    "# all be unique\n",
    "indexer = bmu._get_indexer()\n",
    "\n",
    "# Now we'll concatenate each documents.dat that was returned by _common_files\n",
    "_=[bmu.concatenate_dat(i) for i in list_files]\n",
    "\n",
    "# Now we'll try and get the a clean and full as possible df and store it in a new folder\n",
    "\n",
    "df_articles_concat = pd.read_csv(bmu.PATH_DAT_CONCATENATED + 'articles.dat', \n",
    "                                     sep=\"\\t\", \n",
    "                                     index_col='Pub_id')\n",
    "filtre_DOI_NA = (df_articles_concat['DOI'].isna())\n",
    "df_inter_1=df_articles_concat[~filtre_DOI_NA]\n",
    "df_inter_2 = df_articles_concat[filtre_DOI_NA]\n",
    "\n",
    "[df_no_doubles,L]=bmu.df_with_no_more_doubles()\n",
    "\n",
    "LL=[]\n",
    "df_LL = []\n",
    "\n",
    "# _ = [(LL.append(A[0]), df_LL.append(A[1])) : A = bmu.get_the_doubles(i,df_inter_1,df_inter_2,df_articles_concat) for i in L]\n",
    "\n",
    "for i in L:\n",
    "    A = bmu.get_the_doubles(i,df_inter_1,df_inter_2,df_articles_concat)\n",
    "    LL.append(A[1])\n",
    "    df_LL.append(A[0])\n",
    "\n",
    "# Il reste l'import vers déduplicated à faire\n",
    "\n",
    "bmu.complete_deduplicate_and_save_articles(list_df_dup = df_LL)\n",
    "\n",
    "list_files_without_articles = list_files\n",
    "list_files_without_articles.remove('articles.dat')\n",
    "\n",
    "_ = [bmu.deduplicated_all_but_articles(file_name) for file_name in list_files_without_articles]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dc3fe7e-6382-4ecc-8557-e851edb98b47",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "BiblioMeter_Utils",
   "language": "python",
   "name": "bibliometer_utils"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
