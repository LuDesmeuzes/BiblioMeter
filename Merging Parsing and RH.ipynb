{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "416f0840-c60e-4c4c-a488-778ec57a0b3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "import BiblioMeter_Utils as bmu"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22a37042-6988-4a86-ab58-1cb92c3230bd",
   "metadata": {},
   "source": [
    "La cellule ci dessous récupère le nom de chaque feuille du document excel fourni par Jenny et créer une liste nommée list_annee les contenant dans des sous listes de chaque année"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "24355360-79d9-4b56-baa5-67b4e8ac91fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "Mois = ['01','02','03','04','05','06','07','08','09','10','11','12']\n",
    "\n",
    "Annees = ['2019','2020','2021']\n",
    "\n",
    "annee_2019 = []\n",
    "annee_2020 = []\n",
    "annee_2021 = []\n",
    "\n",
    "fichier_RH = pd.ExcelFile(bmu.PATH_TO_EFFECTIFS)\n",
    "sheet_names=fichier_RH.sheet_names\n",
    "sheet_names.reverse()\n",
    "\n",
    "\n",
    "for i in sheet_names:\n",
    "    if '2019' in i:\n",
    "        annee_2019.append(i)\n",
    "    if '2020' in i:\n",
    "        annee_2020.append(i)\n",
    "    if '2021' in i:\n",
    "        annee_2021.append(i)\n",
    "\n",
    "list_annee = [annee_2019,annee_2020,annee_2021]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d1bec6b-b806-4fdb-997f-0374cebee480",
   "metadata": {},
   "source": [
    "La cellule ci dessous va lire le fichier Effectifs.xlsx pour l'exporter sour un format DF exploitable avec pandas sur python\n",
    "\n",
    "list_de_list_de_df : est une liste de liste de taille mois*année qui contient les informations des employers du LITEN sous forme de DF\n",
    "\n",
    "Lors de cette extraction nous rajoutons une colonne de la forme 'mmaaaa' pour savoir de quelle année vient l'information personnel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0ab0b462-4941-4e53-b68d-70fe96fc3293",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "list_de_list_de_df = []\n",
    "for i in range(len(list_annee)):\n",
    "    list_de_df = []\n",
    "    for j in list_annee[i]:\n",
    "        df = pd.read_excel(bmu.PATH_TO_EFFECTIFS, sheet_name=j)\n",
    "        df['mmaaaa'] = [j] * df.shape[0]\n",
    "        list_de_df.append(df)\n",
    "    \n",
    "    list_de_list_de_df.append(list_de_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "179efb86-44bd-431a-b34c-df9ca9f3acce",
   "metadata": {},
   "source": [
    "La cellule ci dessous reprend list_de_list_de_df, pour créer une liste longue du nombre d'année et qui rassemble toutes les pages du fichier Effectfs.xlsx de chaque mois par année"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6c2801aa-0d39-4d7f-b72b-641e1c0a539c",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_de_df_par_annee = []\n",
    "\n",
    "for i in range(len(list_annee)):\n",
    "    df_par_annee = pd.DataFrame()\n",
    "    for j in range(len(list_annee[i])):\n",
    "        df_par_annee = df_par_annee.append(list_de_list_de_df[i][j])\n",
    "        df_par_annee.reset_index(drop=True, inplace=True)\n",
    "    list_de_df_par_annee.append(df_par_annee)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9f16339-7da9-44e1-a83a-969ce5966125",
   "metadata": {},
   "source": [
    "Celle ci rassemble tout le document sur la même DF avec duplication du personnel\n",
    "\n",
    "df_effectifs : df de tous les documents RH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9ea2efc3-8545-41b6-8eb6-eaa408c578b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_effectifs = pd.DataFrame()\n",
    "\n",
    "for i in range(len(list_de_df_par_annee)):\n",
    "    df_effectifs = df_effectifs.append(list_de_df_par_annee[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c19e64f2-e1a4-4f92-a652-130f928514c2",
   "metadata": {},
   "source": [
    "La cellule de dessous reprendre list_de_df_par_annee et rassemble les matricules identiques sur la même ligne et concatenate en une seule liste 'mmaaaa' et 'Dpt/DOB (lib court)'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8b7372d2-d777-4703-a018-5504bb6654f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_effectifs\n",
    "\n",
    "dg_mmaaa = pd.DataFrame.from_dict({x[0]:[x[1]['mmaaaa'].tolist()] for x in df.groupby(['Matricule'])}).T\n",
    "dg_mmaaa.index.name = 'Matricule'\n",
    "dg_mmaaa.columns = ['list of mmaaaa']\n",
    "dg_mmaaa.reset_index(inplace = True)\n",
    "\n",
    "dg_depart = pd.DataFrame.from_dict({x[0]:[x[1]['Dpt/DOB (lib court)'].tolist()] for x in df.groupby(['Matricule'])}).T\n",
    "dg_depart.index.name = 'Matricule'\n",
    "dg_depart.columns = ['list of Dpt/DOB (lib court)']\n",
    "dg_depart.reset_index(inplace = True)\n",
    "\n",
    "df = pd.merge(df, dg_mmaaa, how = 'left', left_on = ['Matricule'], right_on = ['Matricule'])\n",
    "df = pd.merge(df, dg_depart, how = 'left', left_on = ['Matricule'], right_on = ['Matricule'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "72b972bd-b5fd-4711-91fd-2b88ab04056e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ld259969\\Documents\\PyVenv\\BiblioMeterDraft\\venv\\lib\\site-packages\\pandas\\core\\indexing.py:1732: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_single_block(indexer, value, name)\n"
     ]
    }
   ],
   "source": [
    "# Récupérer les auteurs LITEN\n",
    "df_authorsinst = pd.read_csv(bmu.PATH_DAT_DEDUPLICATED + 'authorsinst.dat', \n",
    "                 sep=\"\\t\")\n",
    "\n",
    "df_authors = pd.read_csv(bmu.PATH_DAT_DEDUPLICATED + 'authors.dat', \n",
    "                 sep=\"\\t\")\n",
    "\n",
    "# Et les associés aux publications\n",
    "df_articles = pd.read_csv(bmu.PATH_DAT_DEDUPLICATED + 'articles.dat', \n",
    "                 sep=\"\\t\")\n",
    "\n",
    "df_authorsinst_authors = pd.merge(df_authorsinst, \n",
    "                     df_authors, \n",
    "                     how = 'left', left_on = ['Pub_id','Idx_author'], right_on = ['Pub_id','Idx_author'])\n",
    "\n",
    "filt_authors_LITEN = (df_authorsinst_authors['Secondary_institutions'] == 'LITEN')\n",
    "list_authors_LITEN = set(df_authorsinst_authors[filt_authors_LITEN]['Co_author'].tolist())\n",
    "\n",
    "merged_df_Liten = pd.merge(df_authorsinst_authors[filt_authors_LITEN], \n",
    "                     df_articles, \n",
    "                     how = 'left', left_on = ['Pub_id'], right_on = ['Pub_id'])\n",
    "\n",
    "merged_df_Liten['Co_author'] = merged_df_Liten['Co_author'].str.upper()\n",
    "merged_df_Liten['Co_author'] = merged_df_Liten['Co_author'].str.split()\n",
    "\n",
    "# Ci dessous sert à créer une colonne et à mettre sous le bon format le nom des co auteurs.\n",
    "\n",
    "merged_df_Liten['Co_author_joined'] = merged_df_Liten['Co_author']\n",
    "for i in range(len(merged_df_Liten)):\n",
    "    length = len(merged_df_Liten['Co_author'][i])\n",
    "    merged_df_Liten['Co_author_joined'].iloc[i] = (' ').join(merged_df_Liten['Co_author'][i][0:length-1])\n",
    "    \n",
    "print('Done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2c31cda7-fbfd-4fa3-95fb-690e0943b792",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Création du fichier RH epuré\n",
    "fichier_rh = df.drop_duplicates(subset='Matricule')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c9611a47-0b06-4154-a88c-56c71015f59c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selection des colonness pratique pour une visu plus lisible\n",
    "# CES COLONNES NE SONT PAS LES COLONNES DEFINITIVES, CEST SIMPLEMENT POUR RENDRE LISIBLE LE FICHIER EXCEL DE TEST\n",
    "\n",
    "ce_que_je_veux_voir_publi = ['Pub_id', 'Idx_author', 'Authors', 'Co_author_joined', 'DOI', 'ISSN', 'Secondary_institutions']\n",
    "df_Liten = merged_df_Liten[ce_que_je_veux_voir_publi]\n",
    "\n",
    "ce_que_je_veux_voir_RH =['Matricule', 'Nom', 'Prénom', 'Dpt/DOB (lib court)',\n",
    "       'Service (lib court)', 'Laboratoire (lib court)', 'Laboratoire (lib long)']\n",
    "df_fichierRH = fichier_rh[ce_que_je_veux_voir_RH]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4e31c4a-2239-425c-b51d-ed22ad103a71",
   "metadata": {},
   "source": [
    "#### Ici on crée dj_jp, df destinée à être envoyée vers un fichier excel pour JP après quelques traitements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5a4661f3-9574-43b3-9b75-d65868f87ed6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    }
   ],
   "source": [
    "# Required imports for similarity function\n",
    "from difflib import SequenceMatcher\n",
    "import numpy as np\n",
    "import itertools\n",
    "similarity = lambda x: np.mean([SequenceMatcher(None, a,b).ratio() for a,b in itertools.combinations(x, 2)])\n",
    "\n",
    "df_jp = pd.DataFrame() # La df qui retrouve les personnes dans le fichier RH\n",
    "df_orphelin = pd.DataFrame() # La df qui retrouve pas les personnes dans le fichier RH\n",
    "counter = [] # Une liste pour plus tard qui nous permettra de colorer les bonnes lignes\n",
    "\n",
    "for i in range(len(merged_df_Liten)):\n",
    "\n",
    "    df_inter_merged = merged_df_Liten.iloc[i]\n",
    "    df_inter_rh = fichier_rh[fichier_rh['Nom'] == df_inter_merged['Co_author_joined']]\n",
    "\n",
    "    if len(df_inter_rh) != 0:\n",
    "\n",
    "        list_similarity = []\n",
    "\n",
    "        _ = [list_similarity.append(similarity([df_inter_rh['Prénom'].iloc[j], df_inter_merged['Co_author'][1]])) for j in range(len(df_inter_rh))]\n",
    "\n",
    "        emplacement_du_max = [i for i, x in enumerate(list_similarity) if x == max(list_similarity)]\n",
    "\n",
    "        if max(list_similarity) == 0:\n",
    "            df_orphelin = df_orphelin.append(df_inter_merged)\n",
    "\n",
    "        if len(list_similarity) > 1 and len(emplacement_du_max) > 1:\n",
    "\n",
    "            for j in emplacement_du_max:\n",
    "                df_inter_jp = pd.DataFrame()\n",
    "                df_inter_jp = pd.merge(df_inter_merged.to_frame().T, \n",
    "                                 df_inter_rh.iloc[j].to_frame().T, \n",
    "                                 how = 'left', left_on = ['Co_author_joined'], right_on = ['Nom'])\n",
    "                df_jp = df_jp.append(df_inter_jp, ignore_index = True)\n",
    "                counter.append(len(df_jp))\n",
    "        else:\n",
    "            df_inter_jp = pd.DataFrame()\n",
    "            df_inter_jp = pd.merge(df_inter_merged.to_frame().T, \n",
    "                                 df_inter_rh.iloc[emplacement_du_max], \n",
    "                                 how = 'left', left_on = ['Co_author_joined'], right_on = ['Nom'])\n",
    "            df_jp = df_jp.append(df_inter_jp, ignore_index = True)\n",
    "\n",
    "    else:\n",
    "        df_orphelin = df_orphelin.append(df_inter_merged)\n",
    "\n",
    "print('Done')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6117a20-2969-4822-acc7-0172db65c5f2",
   "metadata": {},
   "source": [
    "#### LA ON VA ESSAYER D'AJOUTER LES OTPs (nom de la fonction à changer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "01a1ae72-2d0f-4879-b371-222e733095f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "_=[bmu.you_got_OTPed(df_jp,i) for i in range(len(df_jp))]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3ef8216-b1b8-4a71-aced-22f8835cabc7",
   "metadata": {},
   "source": [
    "#### Ca fonctionne, mais pas encore avec le choix multiple, on va le rajouter par dessus ! (Dans le workbook)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c2d3eccc-000d-449c-a289-4882ae48223c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ce_que_je_veux_voir_JP = ce_que_je_veux_voir_publi + ce_que_je_veux_voir_RH + ['List_of_OTP']\n",
    "ce_que_je_veux_voir_JP.remove('Pub_id')\n",
    "df_jp.set_index(['Pub_id'], inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bbc92331-c114-447c-b236-1ba51561f16b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    }
   ],
   "source": [
    "# Creating the workbook\n",
    "from openpyxl import Workbook, load_workbook\n",
    "from openpyxl.worksheet.datavalidation import DataValidation\n",
    "from openpyxl.utils.dataframe import dataframe_to_rows\n",
    "from openpyxl.styles import Font, PatternFill\n",
    "\n",
    "wb = Workbook()\n",
    "ws = wb.active\n",
    "ws.title = 'Publi x Effectifs'\n",
    "\n",
    "ft = PatternFill(fgColor = '00FFFF00', fill_type = \"solid\")\n",
    "\n",
    "for r in dataframe_to_rows(df_jp[ce_que_je_veux_voir_JP], index=True, header=True):\n",
    "    ws.append(r)\n",
    "    last_row = ws[ws.max_row]\n",
    "    if ws.max_row-2 in counter:\n",
    "        for col in range(len(last_row)):\n",
    "            cell = last_row[col]\n",
    "            cell.fill = ft\n",
    "\n",
    "for cell in ws['A'] + ws[1]:\n",
    "    cell.style = 'Pandas'\n",
    "\n",
    "for r in range(0,ws.max_row-2):\n",
    "    \n",
    "    validation_list = bmu.liste_de_validation(df_jp,r)\n",
    "    \n",
    "    data_val = DataValidation(type=\"list\",formula1=validation_list)\n",
    "    ws.add_data_validation(data_val)\n",
    "\n",
    "    data_val.add(ws[\"O\"+str(r+3)])\n",
    "\n",
    "wb.save(bmu.PATH_JP + 'PubliXEffectifs_version_6.xlsx')\n",
    "\n",
    "print('Done')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f8c2d7d-7e85-45a0-b50c-ab5f4958e09f",
   "metadata": {},
   "source": [
    "#### Insatifait du choix multiple, il n'est pas multiple... solution trouvé avec Kutools for excel, mais à explorer encore autre part\n",
    "\n",
    "#### Le code couleur pour le moment veut dire qu'il faut faire un choix dans les lignes jaunes consécutives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "815ca2ec-8020-4997-a00b-498466c1d68c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "BiblioMeter_Utils",
   "language": "python",
   "name": "bibliometer_utils"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
