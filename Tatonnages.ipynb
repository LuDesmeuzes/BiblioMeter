{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e8cc0f67-c2cc-4324-b449-80422c67e2bf",
   "metadata": {},
   "source": [
    "# User environment settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d16453c0-f6e8-43df-b200-52bc6ebf45f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Corpuses folder: C:\\Users\\ld259969\\Documents\\PyVenv\\BiblioMeterDraft\\Liten_Corpuses\n",
      "Effectif folder: C:\\Users\\ld259969\\Documents\\PyVenv\\BiblioMeterDraft\\Liten_Effectifs\n",
      "Configuration folder: C:\\Users\\ld259969\\Documents\\PyVenv\\BiblioMeterDraft\\Liten_Corpuses\\Configuration_Files\n",
      "Selection folder: C:\\Users\\ld259969\\Documents\\PyVenv\\BiblioMeterDraft\\Liten_Corpuses\\Configuration_Files\\Selection_Files\n",
      "Rep_utils: C:\\Users\\ld259969\\Documents\\PyVenv\\BiblioMeterDraft\\BiblioAnalysis_RefFiles\n"
     ]
    }
   ],
   "source": [
    "# Standard library imports\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "#Local library imports\n",
    "# Local imports\n",
    "import BiblioAnalysis_Utils_Ludo as bau\n",
    "\n",
    "## User identification\n",
    "root = Path.home()\n",
    "\n",
    "user = {\n",
    "    'user_id' : 'Ludo',\n",
    "    'mac_packages' : '',\n",
    "    'path1' : 'Documents/PyVenv/BiblioMeterDraft/',\n",
    "    'path2' : 'Liten_Corpuses/',\n",
    "    'path21' : 'Liten_Effectifs/',\n",
    "    'path3' : 'Configuration_Files/',\n",
    "    'path4' : 'Selection_Files/',\n",
    "    'path5' : '',\n",
    "    }\n",
    "\n",
    "## Folder containing the general useful files\n",
    "rep_utils = root / Path(user['path1'] + 'BiblioAnalysis_RefFiles/')\n",
    " # Specific files for scopus type database in this folder\n",
    "scopus_cat_codes = 'scopus_cat_codes.txt'\n",
    "scopus_journals_issn_cat = 'scopus_journals_issn_cat.txt'\n",
    "\n",
    "## Getting complementary information from user  \n",
    "user_id =  user['user_id']\n",
    "expert =  False\n",
    "corpuses_folder = root / Path(user['path1'] +  user['path2'])\n",
    "effectif_folder = root / Path(user['path1'] +  user['path21'])\n",
    "config_folder = root / Path(user['path1'] + user['path2'] + user['path3'])\n",
    "select_folder = config_folder / Path(user['path4'])\n",
    "\n",
    "## Printing useful information\n",
    "print('Corpuses folder:', corpuses_folder)\n",
    "print('Effectif folder:', effectif_folder)\n",
    "print('Configuration folder:', config_folder)\n",
    "print('Selection folder:', select_folder)\n",
    "print('Rep_utils:', rep_utils)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01514dce-9e60-4853-9f62-069a04d481cd",
   "metadata": {},
   "source": [
    "## I - Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39e28cc2-10c3-4364-998f-6c552f64b32d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard library imports\n",
    "import os\n",
    "from pathlib import Path\n",
    "from IPython.display import clear_output\n",
    "\n",
    "## Selection of corpus file\n",
    "corpusfiles_list = os.listdir(corpuses_folder)\n",
    "corpusfiles_list.sort()\n",
    "print('Please select the corpus via the tk window')\n",
    "myprojectname = bau.Select_multi_items(corpusfiles_list,'single')[0]+'/'\n",
    "#clear_output(wait=False)\n",
    "project_folder = corpuses_folder /Path(myprojectname)\n",
    "database_type = input('Corpus file type (scopus, wos - default: \"wos\")? ')\n",
    "if database_type =='': database_type = 'wos' \n",
    "#clear_output(wait=True)\n",
    "\n",
    "## Setting the  graph main heading\n",
    "digits_list = list(filter(str.isdigit, myprojectname))\n",
    "corpus_year = ''\n",
    "for i in range(len(digits_list)):corpus_year = corpus_year + digits_list[i]\n",
    "init, end = str(user['path5']).find(\"_\")+1,-1\n",
    "corpus_state = str(user['path5'])[init:end]\n",
    "main_heading = corpus_year + ' Corpus: ' + corpus_state\n",
    "\n",
    "## Printing useful information\n",
    "print('Specific-paths set for user: ', user_id)\n",
    "print('Corpus year:                 ', corpus_year)\n",
    "print('Corpus status:               ', corpus_state)\n",
    "print('Project name:                ', myprojectname)\n",
    "print('Corpus file type:            ', database_type)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd9e7ea5-d524-4dc3-bf62-31ff382f7646",
   "metadata": {},
   "source": [
    "## II - Parsing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0a102b9-4dc1-46ee-9274-c2fe6e61c15a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard libraries import\n",
    "import os\n",
    "import json\n",
    "from pathlib import Path\n",
    "from IPython.display import clear_output\n",
    "\n",
    "# Local imports\n",
    "import BiblioAnalysis_Utils_Ludo as bau\n",
    "\n",
    "## ##################################################\n",
    "## ##################################################\n",
    "## ##################################################\n",
    "## Building the names of the useful folders\n",
    "\n",
    "    # Folder containing the wos or scopus file to process\n",
    "in_dir_parsing = project_folder / Path('rawdata')\n",
    "\n",
    "    # Folder containing the output files of the data parsing \n",
    "out_dir_parsing = project_folder / Path('parsing')\n",
    "if not os.path.exists(out_dir_parsing):\n",
    "    os.mkdir(out_dir_parsing)\n",
    "\n",
    "## Running function biblio_parser\n",
    "parser_done = input(\"Parsing available (y/n)? \")\n",
    "#clear_output(wait=True)\n",
    "if parser_done == \"n\":\n",
    "    bau.biblio_parser(in_dir_parsing, out_dir_parsing, database_type, expert, rep_utils) \n",
    "    with open(Path(out_dir_parsing) / Path('failed.json'), 'r') as failed_json:\n",
    "            data_failed=failed_json.read()\n",
    "    dic_failed = json.loads(data_failed)\n",
    "    articles_number = dic_failed[\"number of article\"]\n",
    "    print(\"Parsing processed on full corpus\")\n",
    "    print(\"\\n\\nSuccess rates\")\n",
    "    del dic_failed['number of article']\n",
    "    for item, value in dic_failed.items():\n",
    "        print(f'    {item}: {value[\"success (%)\"]:.2f}%')\n",
    "else:\n",
    "    parser_filt = input(\"Parsing available without rawdata -from filtering- (y/n)? \")\n",
    "    if parser_filt == \"n\":        \n",
    "        with open(Path(out_dir_parsing) / Path('failed.json'), 'r') as failed_json:\n",
    "            data_failed=failed_json.read()\n",
    "        dic_failed = json.loads(data_failed)\n",
    "        articles_number = dic_failed[\"number of article\"]\n",
    "        #clear_output(wait=True)\n",
    "        print(\"Parsing available from full corpus\")\n",
    "        print(\"\\n\\nSuccess rates\")\n",
    "        del dic_failed['number of article']\n",
    "        for item, value in dic_failed.items():\n",
    "            print(f'    {item}: {value[\"success (%)\"]:.2f}%')\n",
    "    else:\n",
    "        #clear_output(wait=True)\n",
    "        print(\"Parsing available from filtered corpus without rawdata\")\n",
    "        file = project_folder /Path('parsing/' + 'articles.dat')\n",
    "        with open(file) as f:\n",
    "            lines = f.readlines()\n",
    "        articles_number = len(lines)\n",
    "\n",
    "print(\"\\n\\nCorpus parsing saved in folder:\\n\", str(out_dir_parsing))\n",
    "print('\\nNumber of articles in the corpus : ', articles_number)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "396fc39b-f3b6-4c2a-8cea-73aab01f3b0b",
   "metadata": {},
   "source": [
    "# III - Concatenation of the parsed corpuses"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3afa36e-3f22-4625-810b-07ee4dceb1a2",
   "metadata": {},
   "source": [
    "## Get list of fichier.dat en commun"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8fdbc789-b1a6-4cd3-8f0d-879bd610acc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "La liste commune des fichiers.dat est :  ['titlekeywords.dat', 'journalkeywords.dat', 'subjects.dat', 'authorsinst.dat', 'authors.dat', 'addresses.dat', 'institutions.dat', 'references.dat', 'authorskeywords.dat', 'keywords.dat', 'subjects2.dat', 'countries.dat', 'articles.dat']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "Chemin_scopus_parsing='C:/Users/ld259969/Documents/PyVenv/BiblioMeterDraft/Liten_Corpuses/2020_scopus/parsing/'\n",
    "Chemin_wos_parsing='C:/Users/ld259969/Documents/PyVenv/BiblioMeterDraft/Liten_Corpuses/2020_wos/parsing/'\n",
    "Chemin_dat_concatene='C:/Users/ld259969/Documents/PyVenv/BiblioMeterDraft/Liten_Corpuses/concatene/'\n",
    "Chemin_dat_deduplicated='C:/Users/ld259969/Documents/PyVenv/BiblioMeterDraft/Liten_Corpuses/deduplicated/'\n",
    "\n",
    "list_dir_scopus=set(os.listdir(Chemin_scopus_parsing))\n",
    "N_scopus=len(list_dir_scopus)\n",
    "#print(len(list_dir_scopus))\n",
    "list_dir_wos=os.listdir(Chemin_wos_parsing)\n",
    "N_wos=len(list_dir_wos)\n",
    "#print(len(list_dir_wos))\n",
    "\n",
    "len_max=max(N_scopus,N_wos)\n",
    "\n",
    "list_big=list_dir_scopus\n",
    "list_small=list_dir_wos\n",
    "list_commun=[]\n",
    "if N_scopus<N_wos:\n",
    "    list_big=list_dir_wos\n",
    "    list_small=list_dir_scopus\n",
    "    \n",
    "for k in list_big:\n",
    "    if k in list_small:\n",
    "        list_commun.append(k)\n",
    "list_commun.remove('.ipynb_checkpoints')\n",
    "list_commun.remove('failed.json')\n",
    "list_commun.remove('database.dat')\n",
    "print('\\nLa liste commune des fichiers.dat est : ', list_commun)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a02af4d4-9c6a-4d09-96f2-64581797bc50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Concatenation terminée\n"
     ]
    }
   ],
   "source": [
    "import BiblioAnalysis_Utils_Ludo as bau\n",
    "\n",
    "\"\"\" Savoir de combien il faut réindexer \"\"\"\n",
    "\"\"\" Il est nécessaire de récupérer le dernier Pub_id d'un\n",
    "de deux coprus et de le rajouter (+1) au Pub_id de l'autre corpus \"\"\"\n",
    "\n",
    "df_scopus = pd.DataFrame()\n",
    "df_scopus = pd.read_csv(Chemin_scopus_parsing + 'articles.dat',sep=\"\\t\")\n",
    "indexer = df_scopus.shape[0]\n",
    "\n",
    "for i in list_commun:\n",
    "    #print(i)\n",
    "    #df_scopus=pd.DataFrame()\n",
    "    df_scopus = pd.read_csv(Chemin_scopus_parsing + i,sep=\"\\t\")\n",
    "    \n",
    "    #df_wos=pd.DataFrame()\n",
    "    df_wos = pd.read_csv(Chemin_wos_parsing + i,sep=\"\\t\")\n",
    "    df_wos['Pub_id']=df_wos['Pub_id']+indexer\n",
    "    \n",
    "    list_df=[]\n",
    "    list_df=[df_wos,df_scopus]\n",
    "    #df_inter=pd.DataFrame()\n",
    "    df_inter = pd.concat(list_df,ignore_index=False)\n",
    "    df_inter.set_index('Pub_id',inplace=True)\n",
    "    df_inter.sort_index(inplace=True)\n",
    "    \n",
    "    df_inter.to_csv(Chemin_dat_concatene + i,\n",
    "                    index=True,\n",
    "                    columns=df_inter.columns.tolist(),\n",
    "                    sep='\\t',\n",
    "                    header=True)\n",
    "\n",
    "print('Concatenation terminée')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "213a5cc6-dc58-43bd-bf54-6172cad3bb31",
   "metadata": {},
   "source": [
    "## Get list of df of doublons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fe08a2b5-ae77-4798-b14c-1073d4b24a3f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Authors</th>\n",
       "      <th>Year</th>\n",
       "      <th>Journal</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Page</th>\n",
       "      <th>DOI</th>\n",
       "      <th>Document_type</th>\n",
       "      <th>Language</th>\n",
       "      <th>Title</th>\n",
       "      <th>ISSN</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pub_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Boujjat H</td>\n",
       "      <td>2020</td>\n",
       "      <td>Chemical Engineering Science</td>\n",
       "      <td>228</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.1016/j.ces.2020.115970</td>\n",
       "      <td>Article</td>\n",
       "      <td>English</td>\n",
       "      <td>Experimental and CFD investigation of inert be...</td>\n",
       "      <td>0009-2509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Schultheiss A</td>\n",
       "      <td>2020</td>\n",
       "      <td>Journal of Materials Chemistry C</td>\n",
       "      <td>8</td>\n",
       "      <td>17254.0</td>\n",
       "      <td>10.1039/d0tc04899b</td>\n",
       "      <td>Article</td>\n",
       "      <td>English</td>\n",
       "      <td>Water content control during solution-based po...</td>\n",
       "      <td>2050-7534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Profatilova I</td>\n",
       "      <td>2020</td>\n",
       "      <td>ACS Applied Energy Materials</td>\n",
       "      <td>3</td>\n",
       "      <td>11873.0</td>\n",
       "      <td>10.1021/acsaem.0c01999</td>\n",
       "      <td>Article</td>\n",
       "      <td>English</td>\n",
       "      <td>Impact of Silicon/Graphite Composite Electrode...</td>\n",
       "      <td>2574-0962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Murani A</td>\n",
       "      <td>2020</td>\n",
       "      <td>Physical Review B</td>\n",
       "      <td>102</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.1103/PhysRevB.102.214506</td>\n",
       "      <td>Article</td>\n",
       "      <td>English</td>\n",
       "      <td>Long- To short-junction crossover and field-re...</td>\n",
       "      <td>2469-9950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Armand M</td>\n",
       "      <td>2020</td>\n",
       "      <td>Journal of Power Sources</td>\n",
       "      <td>479</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.1016/j.jpowsour.2020.228708</td>\n",
       "      <td>Article</td>\n",
       "      <td>English</td>\n",
       "      <td>Lithium-ion batteries – Current state of the a...</td>\n",
       "      <td>0378-7753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>178</th>\n",
       "      <td>Soulier M</td>\n",
       "      <td>2020</td>\n",
       "      <td>Euro PM 2018 Congress and Exhibition</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Conference Paper</td>\n",
       "      <td>English</td>\n",
       "      <td>Study of 316L stainless steel powders specific...</td>\n",
       "      <td>unknown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179</th>\n",
       "      <td>Philippot C</td>\n",
       "      <td>2020</td>\n",
       "      <td>Euro PM 2018 Congress and Exhibition</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Conference Paper</td>\n",
       "      <td>English</td>\n",
       "      <td>Potential workers exposure measurement in meta...</td>\n",
       "      <td>unknown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>314</th>\n",
       "      <td>Fattori M</td>\n",
       "      <td>2020</td>\n",
       "      <td>2020 IEEE CUSTOM INTEGRATED CIRCUITS CONFERENC...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Proceedings Paper</td>\n",
       "      <td>English</td>\n",
       "      <td>A Fully-Printed Organic Smart Temperature Sens...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>316</th>\n",
       "      <td>Razi R</td>\n",
       "      <td>2020</td>\n",
       "      <td>2020 IEEE INTERNATIONAL CONFERENCE ON INDUSTRI...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>860.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Proceedings Paper</td>\n",
       "      <td>English</td>\n",
       "      <td>Robust hybrid control of parallel inverters fo...</td>\n",
       "      <td>2643-2978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>317</th>\n",
       "      <td>Pham MC</td>\n",
       "      <td>2020</td>\n",
       "      <td>2020 IEEE INTERNATIONAL CONFERENCE ON INDUSTRI...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1178.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Proceedings Paper</td>\n",
       "      <td>English</td>\n",
       "      <td>Power management in multi-microgrid system bas...</td>\n",
       "      <td>2643-2978</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>226 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              Authors  Year  \\\n",
       "Pub_id                        \n",
       "0           Boujjat H  2020   \n",
       "1       Schultheiss A  2020   \n",
       "2       Profatilova I  2020   \n",
       "3            Murani A  2020   \n",
       "4            Armand M  2020   \n",
       "...               ...   ...   \n",
       "178         Soulier M  2020   \n",
       "179       Philippot C  2020   \n",
       "314         Fattori M  2020   \n",
       "316            Razi R  2020   \n",
       "317           Pham MC  2020   \n",
       "\n",
       "                                                  Journal Volume     Page  \\\n",
       "Pub_id                                                                      \n",
       "0                            Chemical Engineering Science    228      NaN   \n",
       "1                        Journal of Materials Chemistry C      8  17254.0   \n",
       "2                            ACS Applied Energy Materials      3  11873.0   \n",
       "3                                       Physical Review B    102      NaN   \n",
       "4                                Journal of Power Sources    479      NaN   \n",
       "...                                                   ...    ...      ...   \n",
       "178                  Euro PM 2018 Congress and Exhibition    NaN      NaN   \n",
       "179                  Euro PM 2018 Congress and Exhibition    NaN      NaN   \n",
       "314     2020 IEEE CUSTOM INTEGRATED CIRCUITS CONFERENC...    NaN      NaN   \n",
       "316     2020 IEEE INTERNATIONAL CONFERENCE ON INDUSTRI...    NaN    860.0   \n",
       "317     2020 IEEE INTERNATIONAL CONFERENCE ON INDUSTRI...    NaN   1178.0   \n",
       "\n",
       "                                   DOI      Document_type Language  \\\n",
       "Pub_id                                                               \n",
       "0            10.1016/j.ces.2020.115970            Article  English   \n",
       "1                   10.1039/d0tc04899b            Article  English   \n",
       "2               10.1021/acsaem.0c01999            Article  English   \n",
       "3          10.1103/PhysRevB.102.214506            Article  English   \n",
       "4       10.1016/j.jpowsour.2020.228708            Article  English   \n",
       "...                                ...                ...      ...   \n",
       "178                                NaN   Conference Paper  English   \n",
       "179                                NaN   Conference Paper  English   \n",
       "314                                NaN  Proceedings Paper  English   \n",
       "316                                NaN  Proceedings Paper  English   \n",
       "317                                NaN  Proceedings Paper  English   \n",
       "\n",
       "                                                    Title       ISSN  \n",
       "Pub_id                                                                \n",
       "0       Experimental and CFD investigation of inert be...  0009-2509  \n",
       "1       Water content control during solution-based po...  2050-7534  \n",
       "2       Impact of Silicon/Graphite Composite Electrode...  2574-0962  \n",
       "3       Long- To short-junction crossover and field-re...  2469-9950  \n",
       "4       Lithium-ion batteries – Current state of the a...  0378-7753  \n",
       "...                                                   ...        ...  \n",
       "178     Study of 316L stainless steel powders specific...    unknown  \n",
       "179     Potential workers exposure measurement in meta...    unknown  \n",
       "314     A Fully-Printed Organic Smart Temperature Sens...        NaN  \n",
       "316     Robust hybrid control of parallel inverters fo...  2643-2978  \n",
       "317     Power management in multi-microgrid system bas...  2643-2978  \n",
       "\n",
       "[226 rows x 10 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_articles_concat = pd.read_csv(Chemin_dat_concatene + '/articles.dat',sep=\"\\t\",index_col='Pub_id')\n",
    "\n",
    "# Virer les lignes non exploitables (Title et Document_type non renseignés)\n",
    "filtre_Title_DT = (df_articles_concat['Title'].isna()) & (df_articles_concat['Document_type'].isna())\n",
    "filtre_Title_DOI = (df_articles_concat['Title'].isna()) & (df_articles_concat['DOI'].isna())\n",
    "df_articles_concat=df_articles_concat[~filtre_Title_DOI]\n",
    "df_articles_concat=df_articles_concat[~filtre_Title_DT]\n",
    "\n",
    "# On récupère un indice unique des duplicats sur le DOI, on traitera les cas particulier après. \n",
    "# On les retire donc pour les gérer séparement en les rajouter à la DF une fois traités\n",
    "# Pour ce faire on va utiliser DateFrame.drop_duplicates pour récupérer l'index\n",
    "# On les rajoutera après\n",
    "\n",
    "filtre_DOI_NA = (df_articles_concat['DOI'].isna())\n",
    "df_inter_1=df_articles_concat[~filtre_DOI_NA]\n",
    "\n",
    "df_inter_1 = df_inter_1.drop_duplicates(subset=['DOI'],keep='first')\n",
    "\n",
    "# On rajoute les articles sans DOI\n",
    "df_inter_2 = pd.concat([df_inter_1,df_articles_concat[filtre_DOI_NA]])\n",
    "                        \n",
    "# Pour gérer les DOI isna(), on va simplement récépérer la DataFrame qui ne possède que les DOI isna()\n",
    "# On fera un filtre sur la colonne Title et Document_type (sinon risque de perdre de l'information)\n",
    "\n",
    "#df_empty_DOI = df_articles_concat[filtre_DOI_NA]\n",
    "#df_inter_2 = df_empty_DOI.drop_duplicates(subset=['Document_type','Title'], keep='first')\n",
    "\n",
    "#df_no_doubles=pd.concat([df_inter_1,df_inter_2],ignore_index=False)\n",
    "\n",
    "df_no_doubles = df_inter_2.drop_duplicates(subset=['Document_type','Title'],keep='first')\n",
    "\n",
    "indices_of_duplicates = df_no_doubles.index\n",
    "df_no_doubles\n",
    "#df_inter_2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0ed3a8e-32f3-4fe6-b320-c397c51de446",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Choose which one to keep and get rid of the other(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7d4c31b1-5949-45e0-8456-8434e9afcbc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_df_dup=[]\n",
    "list_of_indices_of_duplicates=[]\n",
    "# Même raison que pour la partie du dessus, il est nécessaire de gérer les cas sans DOI à part \n",
    "# On enlève les individus sans DOI, puis on cherche les doublons avec seulement ceux qui présente des DOI\n",
    "filtre_DOI_NA = (df_articles_concat['DOI'].isna())\n",
    "df_inter_1=df_articles_concat[~filtre_DOI_NA]\n",
    "\n",
    "# On va s'occuper des individus sans DOI maintenant\n",
    "df_inter_2 = df_articles_concat[filtre_DOI_NA]\n",
    "\n",
    "for i in indices_of_duplicates:\n",
    "    \n",
    "        df_inter_DOI = pd.DataFrame()\n",
    "        df_inter_Title = pd.DataFrame()\n",
    "        df_inter_inter = pd.DataFrame()\n",
    "        df_inter = pd.DataFrame()\n",
    "        \n",
    "        filt_inter_DOI = (df_inter_1['DOI'] == df_articles_concat['DOI'].loc[i]) # Renvoie un filtre intermédiaire des mêmes DOI\n",
    "        df_inter_DOI = df_inter_1[filt_inter_DOI] # On récupère une DF avec les doublons, pour permettre de choisir quoi garder ensuite\n",
    "        \n",
    "        filt_inter_Title_DT = (df_inter_2['Title'] == df_articles_concat['Title'].loc[i]) & (df_inter_2['Document_type'] == df_articles_concat['Document_type'].loc[i])\n",
    "        df_inter_Title_DT = df_inter_2[filt_inter_Title_DT]\n",
    "        \n",
    "        if df_inter_DOI.index.tolist() != df_inter_Title_DT.index.tolist():\n",
    "            df_inter = pd.concat([df_inter_DOI,df_inter_Title_DT])\n",
    "\n",
    "        #filt_inter_DocumentType = (df_inter['Document_type'] == df_articles_concat['Document_type'].iloc[i])\n",
    "        #df_inter= df_inter[filt_inter_DocumentType]\n",
    "        \n",
    "        list_df_dup.append(df_inter) # On stock tout ça dans une liste, facilite l'accès et consultation pour après\n",
    "        \n",
    "        list_of_indices_of_duplicates.append(df_inter.index.tolist())\n",
    "        \n",
    "list_of_indices_of_duplicates.sort()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9975555-0931-47ce-ae07-17d360dd3453",
   "metadata": {},
   "source": [
    "## Compléter les informations manquantes de la première ligne de chaque DF de list_df_dup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "68c1013f-2d19-46d9-8b6b-4b7d93613bf9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Etape terminée\n"
     ]
    }
   ],
   "source": [
    "Chemin_dat_concatene = 'C:/Users/ld259969/Documents/PyVenv/BiblioMeterDraft/Liten_Corpuses/concatene_bis/'\n",
    "Chemin_dat_deduplicated = 'C:/Users/ld259969/Documents/PyVenv/BiblioMeterDraft/Liten_Corpuses/deduplicated_bis/'\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "df_dup_full_unique=pd.DataFrame()\n",
    "tour = 0\n",
    "\n",
    "for i in range(len(list_df_dup)):\n",
    "#for i in range(1):\n",
    "    working_df = list_df_dup[i]\n",
    "    nombre_duplication = working_df.shape[0]\n",
    "    nombre_colonne = working_df.shape[1]\n",
    "    if nombre_duplication != 1:\n",
    "        for j in range(nombre_colonne):\n",
    "            if working_df.iloc[[0],[j]].isna().bool():\n",
    "                for k in range(1,nombre_duplication):\n",
    "                    if working_df.iloc[[k],[j]].isna().bool():\n",
    "                        working_df.iloc[[0],[j]] = working_df.iloc[[k],[j]]\n",
    "\n",
    "    if tour == 0:\n",
    "        tour = 1\n",
    "        df_dup_full_unique = working_df\n",
    "    else:\n",
    "        df_dup_full_unique = pd.concat([df_dup_full_unique,working_df])\n",
    "        \n",
    "df_dup_full_unique.reset_index(inplace = True)\n",
    "\n",
    "df_AAH=pd.DataFrame()        \n",
    "df_AAH = df_AAH.append([df_dup_full_unique[df_dup_full_unique['Pub_id'] == i] for i in indices_of_duplicates])\n",
    "\n",
    "df_AAH.to_csv(Chemin_dat_deduplicated + 'articles.dat',\n",
    "                    index=False,\n",
    "                    columns=df_AAH.columns.tolist(),\n",
    "                    sep='\\t',\n",
    "                    header=True)\n",
    "\n",
    "print('Etape terminée')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "46f8016c-0e0f-41c3-8a3f-96275737a9cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Etape terminée, le dédoublonnage est terminé et les fichiers .dat sont crées\n"
     ]
    }
   ],
   "source": [
    "list_sans_article = ['addresses.dat','authors.dat', 'authorsinst.dat', \n",
    "                     'authorskeywords.dat', 'countries.dat', \n",
    "                     'institutions.dat', 'journalkeywords.dat', 'keywords.dat', \n",
    "                     'references.dat', 'subjects.dat', 'subjects2.dat', 'titlekeywords.dat']\n",
    "\n",
    "for i in list_sans_article:\n",
    "    exported_df = pd.read_csv(Chemin_dat_concatene + i,sep=\"\\t\")\n",
    "    list_df_dup_full=[]\n",
    "    \n",
    "    filt = (exported_df['Pub_id'].isin(indices_of_duplicates))\n",
    "    exported_df=exported_df[filt]\n",
    "\n",
    "    if i == 'authors.dat':\n",
    "        exported_df.sort_values(['Pub_id','Idx_author'], inplace=True)\n",
    "    if i == 'addresses.dat':\n",
    "        exported_df.sort_values(['Pub_id','Idx_address'], inplace=True)\n",
    "            \n",
    "    exported_df.to_csv(Chemin_dat_deduplicated + i,\n",
    "                    index=False,\n",
    "                    columns=exported_df.columns.tolist(),\n",
    "                    sep='\\t',\n",
    "                    header=True)\n",
    "    \n",
    "print('Etape terminée, le dédoublonnage est terminé et les fichiers .dat sont crées')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c979778-fbba-4c71-b56b-395454879c5e",
   "metadata": {},
   "source": [
    "## Création de la DF avant exportation vers fichier Excel pour JP"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ffb63be-e182-4a48-b01f-75e2dfa7f295",
   "metadata": {},
   "source": [
    "A partir de maintenant il est simplement nécessaire de travailler avec les .dat du dossier deduplicated\n",
    "\n",
    "Les étapes suivantes se découpent en 3 parties :"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75b47ba4-6c76-44d3-b42f-e3dcbea587e7",
   "metadata": {},
   "source": [
    "-Mettre le fichier countries.dat et institutions.dat sous le bon format pour l'incorporer à la DF->E"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c1dc49b-a813-4dd7-9d68-57559204d0f7",
   "metadata": {},
   "source": [
    "-Constuire la première partie de la DF->E (articles + countries + institutions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a3de1e3-fbee-43cb-89f2-39a1890a235b",
   "metadata": {},
   "source": [
    "-Faire le lien avec le fichier RH et contruire la DF->E finale"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "900ab8db-4989-4e7f-bf94-27109f222a12",
   "metadata": {},
   "source": [
    "### Mise en forme de countries et institutions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c844a54d-9b63-41fa-b9ab-870425ee64a4",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'country'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m~\\Documents\\PyVenv\\BiblioMeterDraft\\venv\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3360\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3361\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3362\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Documents\\PyVenv\\BiblioMeterDraft\\venv\\lib\\site-packages\\pandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32m~\\Documents\\PyVenv\\BiblioMeterDraft\\venv\\lib\\site-packages\\pandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'country'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_3672/1958761778.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mdf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0msep\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'\\t'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[0mdg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfrom_dict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'; '\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'country'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munique\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgroupby\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Pub_id'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mT\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[0mdg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'Pub_id'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[0mdg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m'country'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_3672/1958761778.py\u001b[0m in \u001b[0;36m<dictcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mdf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0msep\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'\\t'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[0mdg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfrom_dict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'; '\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'country'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munique\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgroupby\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Pub_id'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mT\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[0mdg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'Pub_id'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[0mdg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m'country'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Documents\\PyVenv\\BiblioMeterDraft\\venv\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3456\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3457\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3458\u001b[1;33m             \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3459\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3460\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Documents\\PyVenv\\BiblioMeterDraft\\venv\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3361\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3362\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3363\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3364\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3365\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mis_scalar\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0misna\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhasnans\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'country'"
     ]
    }
   ],
   "source": [
    "Chemin_countries = \"C:/Users/ld259969/Documents/PyVenv/BiblioMeterDraft/Liten_Corpuses/deduplicated/countries.dat\"\n",
    "file = Chemin_countries\n",
    "\n",
    "df = pd.read_csv(file,sep='\\t')\n",
    "\n",
    "dg = pd.DataFrame.from_dict({x[0]:['; '.join(x[1]['country'].unique())] for x in df.groupby(['Pub_id'])}).T\n",
    "dg.index.name = 'Pub_id'\n",
    "dg.columns = ['country']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62b3857e-d884-4447-a3a7-ea578eb43f9b",
   "metadata": {},
   "source": [
    "Les ... suivants sont l'ancienne version longue de la mise en forme"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf906405-0108-4dee-9df1-be87a09f0a66",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "Chemin_countries = 'C:/Users/ld259969/Documents/PyVenv/BiblioMeterDraft/Liten_Corpuses/deduplicated/countries.dat'\n",
    "Chemin_institutions = 'C:/Users/ld259969/Documents/PyVenv/BiblioMeterDraft/Liten_Corpuses/deduplicated/institutions.dat'\n",
    "\n",
    "df_countries = pd.read_csv(Chemin_countries, sep=\"\\t\")\n",
    "df_institutions = pd.read_csv(Chemin_institutions, sep=\"\\t\")\n",
    "\n",
    "list_Pub_id_unique = df_countries['Pub_id'].drop_duplicates().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99ed7442-1fd1-4e49-8a7b-e1d1f78402b7",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "list_de_list_countries = []\n",
    "list_de_list_institutions = []\n",
    "\n",
    "for i in list_Pub_id_unique:\n",
    "    filt_countries = (df_countries['Pub_id'] == i)\n",
    "    filt_institutions = (df_institutions['Pub_id'] == i)\n",
    "    \n",
    "    list_dans_list_countries = []\n",
    "    list_dans_list_institutions = []\n",
    "    \n",
    "    list_dans_list_countries = df_countries[filt_countries]['country'].drop_duplicates().tolist()\n",
    "    list_dans_list_institutions = df_institutions[filt_institutions]['institution'].drop_duplicates().tolist()\n",
    "    \n",
    "    list_de_list_countries.append(list_dans_list_countries)\n",
    "    list_de_list_institutions.append(list_dans_list_institutions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "976fef3b-2bfd-4522-922f-2664a436eccd",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "filt_countries = (df_countries['Pub_id'] == 0)\n",
    "df_countries[filt_countries]['country'].drop_duplicates().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fcf28dc-5e63-4e6b-8fc4-856f5b11ff57",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_try = pd.DataFrame(list_Pub_id_unique, columns = ['Pub_id'])\n",
    "\n",
    "#df_try.at[:,'countries'] = list_de_list_countries\n",
    "df_try.set_index('Pub_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91743545-8667-4aa2-a17a-022ed2499230",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def list_to_string(the_list):\n",
    "    \n",
    "    # initializing list\n",
    "    test_list = the_list\n",
    "\n",
    "    # initializing delim \n",
    "    delim = ''\n",
    "    res=''\n",
    "    tour = 0\n",
    "\n",
    "    # using loop to add string followed by delim \n",
    "    for ele in test_list:\n",
    "        res = res + delim + str(ele)\n",
    "\n",
    "        if tour == 0:\n",
    "            tour = 1\n",
    "            delim = ';'\n",
    "\n",
    "    return res"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b828d553-0a12-4ee4-94be-8c111759ed04",
   "metadata": {},
   "source": [
    "# A quel département appartiens-tu ?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1961e81-e87d-46c8-b1a9-6b2d83462347",
   "metadata": {},
   "source": [
    "Tout d'abord, nous allons créer les chemins d'accès aux feuilles Excel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7a43b6a7-dcb6-4dfa-b178-608bd328dbcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "Mois = ['01','02','03','04','05','06','07','08','09','10','11','12']\n",
    "\n",
    "Annees = ['2019','2020','2021']\n",
    "#list_sheets = ['092021','082021','072021','062021','052021','042021','032021','022021','012021',\n",
    "#               '122020','112020','102020','092020','082020','072020','062020','052020','042020','032020','022020','012020'\n",
    "#               '122019','112019','102019','092019']\n",
    "\n",
    "annee_2019 = []\n",
    "annee_2020 = []\n",
    "annee_2021 = []\n",
    "\n",
    "path_to_effectif = 'C:/Users/ld259969/Documents/PyVenv/BiblioMeterDraft/Effectifs.xlsx'\n",
    "\n",
    "fichier_RH = pd.ExcelFile(path_to_effectif)\n",
    "sheet_names=fichier_RH.sheet_names\n",
    "sheet_names.reverse()\n",
    "\n",
    "\n",
    "for i in sheet_names:\n",
    "    if '2019' in i:\n",
    "        annee_2019.append(i)\n",
    "    if '2020' in i:\n",
    "        annee_2020.append(i)\n",
    "    if '2021' in i:\n",
    "        annee_2021.append(i)\n",
    "\n",
    "list_annee = [annee_2019,annee_2020,annee_2021]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bc086bf-ed3f-45b5-85c0-953b0450a2f5",
   "metadata": {},
   "source": [
    "Maintenant nous allons constuire chaque DF pour chaque année"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d2e59b30-c200-4cff-8492-c7f1a8f799d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_de_list_de_df = []\n",
    "for i in range(len(list_annee)):\n",
    "    list_de_df = []\n",
    "    for j in list_annee[i]:\n",
    "        df = pd.read_excel(path_to_effectif, sheet_name=j)\n",
    "        df['mmaaaa'] = [j] * df.shape[0]\n",
    "        list_de_df.append(df)\n",
    "    \n",
    "    list_de_list_de_df.append(list_de_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "id": "c263ce0d-4382-4752-a322-d090db17116a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Récupérer les auteurs LITEN\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "path = 'C:/Users/ld259969/Documents/PyVenv/BiblioMeterDraft/Liten_Corpuses/deduplicated_bis/'\n",
    "\n",
    "df_authorsinst = pd.read_csv(path + 'authorsinst.dat', \n",
    "                 sep=\"\\t\")\n",
    "\n",
    "df_authors = pd.read_csv(path + 'authors.dat', \n",
    "                 sep=\"\\t\")\n",
    "\n",
    "# Et les associés aux publications\n",
    "df_articles = pd.read_csv(path + 'articles.dat', \n",
    "                 sep=\"\\t\")\n",
    "\n",
    "merged_df = pd.merge(df_authorsinst, \n",
    "                     df_authors, \n",
    "                     how = 'left', left_on = ['Pub_id','Idx_author'], right_on = ['Pub_id','Idx_author'])\n",
    "\n",
    "filt_authors_LITEN = (merged_df['Secondary_institutions'] == 'LITEN')\n",
    "list_authors_LITEN = set(merged_df[filt_authors_LITEN]['Co_author'].tolist())\n",
    "\n",
    "merged_df_bis = pd.merge(merged_df[filt_authors_LITEN], \n",
    "                     df_articles, \n",
    "                     how = 'left', left_on = ['Pub_id'], right_on = ['Pub_id'])\n",
    "\n",
    "merged_df_bis['Co_author'] = merged_df_bis['Co_author'].str.upper()\n",
    "merged_df_bis['Co_author'] = merged_df_bis['Co_author'].str.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b19125d8-0523-4217-aedb-d20d0310f19d",
   "metadata": {},
   "outputs": [],
   "source": [
    "fichier_rh = list_de_list_de_df[2][8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "id": "e2fccb54-ef9a-4379-95d0-fffc1366d13c",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df_bis['Co_author_joined'] = merged_df_bis['Co_author']\n",
    "for i in range(len(merged_df_bis)):\n",
    "    length = len(merged_df_bis['Co_author'][i])\n",
    "    merged_df_bis['Co_author_joined'].iloc[i] = (' ').join(merged_df_bis['Co_author'][i][0:length-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b23f99c-5195-4b2c-b2af-dd56e789a6ce",
   "metadata": {},
   "source": [
    "merged_df_bis + fichier_rh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "id": "5d944f0e-3ebe-49f8-bd59-a1e313a97c32",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_jp = pd.merge(merged_df_bis, \n",
    "                     fichier_rh, \n",
    "                     how = 'inner', left_on = ['Co_author_joined'], right_on = ['Nom'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee9fa74a-aee6-49c6-a1b1-4c5b517755d8",
   "metadata": {},
   "source": [
    "La méthod merge est pas mal mais insuffisante, car il existe trop de cas avec le même nom de famille,\n",
    "il faut donc tester avec le prénom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "8639a199-d83e-452c-b6eb-1c26c45607b0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Matricule</th>\n",
       "      <th>Nom</th>\n",
       "      <th>Prénom</th>\n",
       "      <th>Sexe(lib)</th>\n",
       "      <th>Nationalité (lib)</th>\n",
       "      <th>Catégorie de salarié (lib)</th>\n",
       "      <th>Statut de salarié (lib)</th>\n",
       "      <th>Filière classement (lib)</th>\n",
       "      <th>Qualification classement (lib)</th>\n",
       "      <th>Spécialité poste (lib)</th>\n",
       "      <th>...</th>\n",
       "      <th>Date début contrat</th>\n",
       "      <th>Date dernière entrée</th>\n",
       "      <th>Date de fin de contrat</th>\n",
       "      <th>Dpt/DOB (lib court)</th>\n",
       "      <th>Service (lib court)</th>\n",
       "      <th>Laboratoire (lib court)</th>\n",
       "      <th>Laboratoire (lib long)</th>\n",
       "      <th>Nature de dépenses</th>\n",
       "      <th>TA</th>\n",
       "      <th>mmaaaa</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>427</th>\n",
       "      <td>225655</td>\n",
       "      <td>MARTIN</td>\n",
       "      <td>JEAN-FRÉDÉRIC</td>\n",
       "      <td>Masculin</td>\n",
       "      <td>française</td>\n",
       "      <td>CDI</td>\n",
       "      <td>Annexe 1</td>\n",
       "      <td>Cadres</td>\n",
       "      <td>INGENIEUR CHERCHEUR</td>\n",
       "      <td>ELECTROCHIMIE</td>\n",
       "      <td>...</td>\n",
       "      <td>2009-12-23</td>\n",
       "      <td>2009-12-23</td>\n",
       "      <td>NaT</td>\n",
       "      <td>DEHT</td>\n",
       "      <td>STB</td>\n",
       "      <td>LM</td>\n",
       "      <td>DRT/LITEN/DEHT/STB/LM</td>\n",
       "      <td>10</td>\n",
       "      <td>1.0</td>\n",
       "      <td>092021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>444</th>\n",
       "      <td>227344</td>\n",
       "      <td>MARTIN</td>\n",
       "      <td>JEREMY</td>\n",
       "      <td>Masculin</td>\n",
       "      <td>française</td>\n",
       "      <td>CDI</td>\n",
       "      <td>Annexe 1</td>\n",
       "      <td>Cadres</td>\n",
       "      <td>INGENIEUR CHERCHEUR</td>\n",
       "      <td>ELECTRONI.DE PUISSANCE/PUISSANCES PULSEE</td>\n",
       "      <td>...</td>\n",
       "      <td>2011-11-17</td>\n",
       "      <td>2011-11-17</td>\n",
       "      <td>NaT</td>\n",
       "      <td>DTS</td>\n",
       "      <td>SIRE</td>\n",
       "      <td>LIRE</td>\n",
       "      <td>DRT/LITEN/DTS/SIRE/LIRE</td>\n",
       "      <td>10</td>\n",
       "      <td>1.0</td>\n",
       "      <td>092021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>820</th>\n",
       "      <td>261909</td>\n",
       "      <td>MARTIN</td>\n",
       "      <td>ALEXIS</td>\n",
       "      <td>Masculin</td>\n",
       "      <td>française</td>\n",
       "      <td>CDD rech. scientif.</td>\n",
       "      <td>Annexe 1</td>\n",
       "      <td>Cadres</td>\n",
       "      <td>INGENIEUR CHERCHEUR</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>2020-01-06</td>\n",
       "      <td>2020-01-06</td>\n",
       "      <td>2021-12-31</td>\n",
       "      <td>DEHT</td>\n",
       "      <td>SAMA</td>\n",
       "      <td>LMP</td>\n",
       "      <td>DRT/LITEN/DEHT/SAMA/LMP</td>\n",
       "      <td>20</td>\n",
       "      <td>1.0</td>\n",
       "      <td>092021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>941</th>\n",
       "      <td>264808</td>\n",
       "      <td>MARTIN</td>\n",
       "      <td>MAXIMILIEN</td>\n",
       "      <td>Masculin</td>\n",
       "      <td>française</td>\n",
       "      <td>CDD</td>\n",
       "      <td>Annexe 1</td>\n",
       "      <td>Cadres</td>\n",
       "      <td>INGENIEUR CHERCHEUR</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>2020-11-02</td>\n",
       "      <td>2020-11-02</td>\n",
       "      <td>2021-11-01</td>\n",
       "      <td>DEHT</td>\n",
       "      <td>STP</td>\n",
       "      <td>LSP</td>\n",
       "      <td>DRT/LITEN/DEHT/STP/LSP</td>\n",
       "      <td>20</td>\n",
       "      <td>1.0</td>\n",
       "      <td>092021</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Matricule     Nom         Prénom Sexe(lib) Nationalité (lib)  \\\n",
       "427     225655  MARTIN  JEAN-FRÉDÉRIC  Masculin         française   \n",
       "444     227344  MARTIN         JEREMY  Masculin         française   \n",
       "820     261909  MARTIN         ALEXIS  Masculin         française   \n",
       "941     264808  MARTIN     MAXIMILIEN  Masculin         française   \n",
       "\n",
       "    Catégorie de salarié (lib) Statut de salarié (lib)  \\\n",
       "427                        CDI                Annexe 1   \n",
       "444                        CDI                Annexe 1   \n",
       "820        CDD rech. scientif.                Annexe 1   \n",
       "941                        CDD                Annexe 1   \n",
       "\n",
       "    Filière classement (lib) Qualification classement (lib)  \\\n",
       "427                   Cadres            INGENIEUR CHERCHEUR   \n",
       "444                   Cadres            INGENIEUR CHERCHEUR   \n",
       "820                   Cadres            INGENIEUR CHERCHEUR   \n",
       "941                   Cadres            INGENIEUR CHERCHEUR   \n",
       "\n",
       "                       Spécialité poste (lib)  ... Date début contrat  \\\n",
       "427                             ELECTROCHIMIE  ...         2009-12-23   \n",
       "444  ELECTRONI.DE PUISSANCE/PUISSANCES PULSEE  ...         2011-11-17   \n",
       "820                                       NaN  ...         2020-01-06   \n",
       "941                                       NaN  ...         2020-11-02   \n",
       "\n",
       "    Date dernière entrée Date de fin de contrat Dpt/DOB (lib court)  \\\n",
       "427           2009-12-23                    NaT                DEHT   \n",
       "444           2011-11-17                    NaT                 DTS   \n",
       "820           2020-01-06             2021-12-31                DEHT   \n",
       "941           2020-11-02             2021-11-01                DEHT   \n",
       "\n",
       "    Service (lib court) Laboratoire (lib court)   Laboratoire (lib long)  \\\n",
       "427                 STB                      LM    DRT/LITEN/DEHT/STB/LM   \n",
       "444                SIRE                    LIRE  DRT/LITEN/DTS/SIRE/LIRE   \n",
       "820                SAMA                     LMP  DRT/LITEN/DEHT/SAMA/LMP   \n",
       "941                 STP                     LSP   DRT/LITEN/DEHT/STP/LSP   \n",
       "\n",
       "    Nature de dépenses   TA  mmaaaa  \n",
       "427                 10  1.0  092021  \n",
       "444                 10  1.0  092021  \n",
       "820                 20  1.0  092021  \n",
       "941                 20  1.0  092021  \n",
       "\n",
       "[4 rows x 23 columns]"
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# retirer filtre, on garde info\n",
    "filtre_ingenieur_chercheur = (fichier_rh['Qualification classement (lib)'] == 'INGENIEUR CHERCHEUR')\n",
    "\n",
    "fichier_rh_filtered = fichier_rh[filtre_ingenieur_chercheur]\n",
    "\n",
    "fichier_rh_filtered[fichier_rh_filtered['Nom'] == merged_df_bis['Co_author_joined'][1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "id": "966bf93e-aeba-461f-be24-506be1bade96",
   "metadata": {},
   "outputs": [],
   "source": [
    "lista=['A','ALEXIS']\n",
    "listb=['A','ADRIEN']\n",
    "a=similarity(lista)\n",
    "b=similarity(listb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e6fd67c-9f69-4235-babd-aaf321c1c079",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.25"
      ]
     },
     "execution_count": 239,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "10d9db19-de41-46fb-9b35-4908408c93f9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'fichier_rh' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_18988/2370177365.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0msimilarity\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mSequenceMatcher\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mratio\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mb\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mitertools\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcombinations\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m \u001b[0mfiltre_ingenieur_chercheur\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mfichier_rh\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Qualification classement (lib)'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'INGENIEUR CHERCHEUR'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;31m# fichier_rh_filtered = fichier_rh[filtre_ingenieur_chercheur]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'fichier_rh' is not defined"
     ]
    }
   ],
   "source": [
    "from difflib import SequenceMatcher\n",
    "import numpy as np\n",
    "import itertools\n",
    "import pandas as pd\n",
    "\n",
    "similarity = lambda x: np.mean([SequenceMatcher(None, a,b).ratio() for a,b in itertools.combinations(x, 2)])\n",
    "\n",
    "filtre_ingenieur_chercheur = (fichier_rh['Qualification classement (lib)'] == 'INGENIEUR CHERCHEUR')\n",
    "\n",
    "# fichier_rh_filtered = fichier_rh[filtre_ingenieur_chercheur]\n",
    "\n",
    "fichier_rh_filtered = fichier_rh\n",
    "\n",
    "df_jp = pd.DataFrame()\n",
    "    \n",
    "for i in range(len(merged_df_bis)):\n",
    "    \n",
    "    df_inter_rh = fichier_rh_filtered[fichier_rh_filtered['Nom'] == merged_df_bis['Co_author_joined'][i]]\n",
    "    df_inter_merged = merged_df_bis.iloc[i]\n",
    "    \n",
    "    if len(df_inter_rh)>1:\n",
    "        \n",
    "        list_similarity = []\n",
    "\n",
    "        for j in range(len(df_inter_rh)):\n",
    "            \n",
    "            list_similarity.append(similarity([df_inter_rh['Prénom'].iloc[j], df_inter_merged['Co_author'][1]]))\n",
    "            \n",
    "        emplacement_du_max = list_similarity.index(max(list_similarity))\n",
    "        \n",
    "        df_inter_rh.iloc[emplacement_du_max]\n",
    "        \n",
    "        df_inter_jp = pd.DataFrame()\n",
    "        \n",
    "        df_inter_jp = df_inter_rh.iloc[emplacement_du_max]\n",
    "        \n",
    "        df_inter_jp = df_inter_jp.append(df_inter_merged) \n",
    "        \n",
    "        df_jp = df_jp.append(df_inter_jp, ignore_index = True)\n",
    "    \n",
    "    if len(df_inter_rh) == 1:\n",
    "        \n",
    "        df_inter_jp = pd.DataFrame()\n",
    "        \n",
    "        df_inter_jp = df_inter_rh.iloc[0]\n",
    "        \n",
    "        df_inter_jp = df_inter_jp.append(df_inter_merged)\n",
    "        \n",
    "        df_jp = df_jp.append(df_inter_jp, ignore_index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "2b6de3a8-d61d-41be-9586-2831b3dda64b",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Matricule                                                                    261909\n",
       "Nom                                                                          MARTIN\n",
       "Prénom                                                                       ALEXIS\n",
       "Sexe(lib)                                                                  Masculin\n",
       "Nationalité (lib)                                                         française\n",
       "Catégorie de salarié (lib)                                      CDD rech. scientif.\n",
       "Statut de salarié (lib)                                                    Annexe 1\n",
       "Filière classement (lib)                                                     Cadres\n",
       "Qualification classement (lib)                                  INGENIEUR CHERCHEUR\n",
       "Spécialité poste (lib)                                                          NaN\n",
       "Nature de contrat (lib)                                          CDD à Objet Défini\n",
       "Annexe classement                                                                 1\n",
       "Date d'effet classement                                         2020-01-06 00:00:00\n",
       "Date début contrat                                              2020-01-06 00:00:00\n",
       "Date dernière entrée                                            2020-01-06 00:00:00\n",
       "Date de fin de contrat                                          2021-12-31 00:00:00\n",
       "Dpt/DOB (lib court)                                                            DEHT\n",
       "Service (lib court)                                                            SAMA\n",
       "Laboratoire (lib court)                                                         LMP\n",
       "Laboratoire (lib long)                                      DRT/LITEN/DEHT/SAMA/LMP\n",
       "Nature de dépenses                                                               20\n",
       "TA                                                                              1.0\n",
       "mmaaaa                                                                       092021\n",
       "Pub_id                                                                            2\n",
       "Idx_author                                                                        6\n",
       "Address                           University Grenoble Alpes, CEA-Liten, Grenoble...\n",
       "Country                                                                      France\n",
       "Institution                                               University Grenoble Alpes\n",
       "Secondary_institutions                                                        LITEN\n",
       "Co_author                                                               [MARTIN, A]\n",
       "Authors                                                               Profatilova I\n",
       "Year                                                                           2020\n",
       "Journal                                                ACS Applied Energy Materials\n",
       "Volume                                                                            3\n",
       "Page                                                                        11873.0\n",
       "DOI                                                          10.1021/acsaem.0c01999\n",
       "Document_type                                                               Article\n",
       "Language                                                                    English\n",
       "Title                             Impact of Silicon/Graphite Composite Electrode...\n",
       "ISSN                                                                      2574-0962\n",
       "Co_author_joined                                                             MARTIN\n",
       "dtype: object"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_inter_jp = pd.DataFrame()\n",
    "df_inter_jp = df_inter_rh.iloc[emplacement_du_max]\n",
    "df_inter_jp.append(df_inter_merged) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3824ca46-706a-4ac6-81d3-e12ee5a044bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(df_jp)):\n",
    "    df_jp['Co_author'].iloc[i]=(' ').join(df_jp['Co_author'].iloc[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "id": "bf2daad6-0c49-4f44-8b4f-5518661a1970",
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH_JP = 'C:/Users/ld259969/Documents/PyVenv/BiblioMeterDraft/Liten_Corpuses/JP/'\n",
    "\n",
    "df_jp = df_jp.sort_values(by=['Matricule','Pub_id'])\n",
    "\n",
    "df_jp[colonnes_utiles].to_excel(PATH_JP + 'excel_jp_version_du_soir.xlsx', \n",
    "             index=False, \n",
    "             columns=colonnes_utiles, \n",
    "             header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "2628a149-9c21-4a2d-bb29-609948f18588",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(df_jp)):\n",
    "    df_jp['Co_author'].iloc[i]=(' ').join(df_jp['Co_author'].iloc[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "f51ca670-c7ed-4be8-a110-85756f59e70c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "89                         M   A   R   T   I   N       A\n",
       "91         C   H   A   N   D   E   S   R   I   S       M\n",
       "123                    P   O   R   C   H   E   R       W\n",
       "57                         F   A   N   G   E   T       O\n",
       "62                             G   U   T   E   L       E\n",
       "                             ...                        \n",
       "169    N       G       U       Y       E       N     ...\n",
       "67     G       U       T       E       L               T\n",
       "0      G                               E             ...\n",
       "106    A                                             ...\n",
       "182    C       H       A       V       I       L     ...\n",
       "Name: Co_author, Length: 190, dtype: object"
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_jp['Co_author']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "id": "e84bab51-16d5-4ee1-a91d-5882ef362299",
   "metadata": {},
   "outputs": [],
   "source": [
    "colonnes_utiles = ['DOI','Annexe classement','Dpt/DOB (lib court)','Service (lib court)','Laboratoire (lib court)',\n",
    "                   'Laboratoire (lib long)','Pub_id','Address','Country','Institution','Secondary_institutions','Co_author_joined','Authors','Year','Journal','Volume','Page',\n",
    "                   'Document_type',\n",
    "                   'Language',\n",
    "                   'Title', \n",
    "                   'ISSN','Matricule','Nom','Prénom','Co_author','Sexe(lib)','Nationalité (lib)',\n",
    "                   'Catégorie de salarié (lib)',\n",
    "                   'Statut de salarié (lib)',\n",
    "                   'Filière classement (lib)',\n",
    "                   'Qualification classement (lib)',\n",
    "                   'Spécialité poste (lib)',\n",
    "                   'Nature de contrat (lib)']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8f8e441f-5378-4518-87df-6f48a7369e15",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_de_df_par_annee = []\n",
    "\n",
    "for i in range(len(list_annee)):\n",
    "    df_par_annee = pd.DataFrame()\n",
    "    for j in range(len(list_annee[i])):\n",
    "        df_par_annee = df_par_annee.append(list_de_list_de_df[i][j])\n",
    "        df_par_annee.reset_index(drop=True, inplace=True)\n",
    "    list_de_df_par_annee.append(df_par_annee)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "a1cf842d-6495-4127-8ac9-78b670b63232",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Matricule</th>\n",
       "      <th>Nom</th>\n",
       "      <th>Prénom</th>\n",
       "      <th>Sexe(lib)</th>\n",
       "      <th>Nationalité (lib)</th>\n",
       "      <th>Catégorie de salarié (lib)</th>\n",
       "      <th>Statut de salarié (lib)</th>\n",
       "      <th>Filière classement (lib)</th>\n",
       "      <th>Qualification classement (lib)</th>\n",
       "      <th>Spécialité poste (lib)</th>\n",
       "      <th>...</th>\n",
       "      <th>Date début contrat</th>\n",
       "      <th>Date dernière entrée</th>\n",
       "      <th>Date de fin de contrat</th>\n",
       "      <th>Dpt/DOB (lib court)</th>\n",
       "      <th>Service (lib court)</th>\n",
       "      <th>Laboratoire (lib court)</th>\n",
       "      <th>Laboratoire (lib long)</th>\n",
       "      <th>Nature de dépenses</th>\n",
       "      <th>TA</th>\n",
       "      <th>mmaaaa</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>67942</td>\n",
       "      <td>CLEMENT</td>\n",
       "      <td>PATRICE</td>\n",
       "      <td>Masculin</td>\n",
       "      <td>française</td>\n",
       "      <td>Conseiller Scient.</td>\n",
       "      <td>Conseiller Scient.NR</td>\n",
       "      <td>NaN</td>\n",
       "      <td>CONSEILLER SCIENTIFIQUE</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>2019-08-01</td>\n",
       "      <td>2012-08-01</td>\n",
       "      <td>2020-07-31</td>\n",
       "      <td>DTBH</td>\n",
       "      <td>SCTR</td>\n",
       "      <td>LER</td>\n",
       "      <td>DRT/LITEN/DTBH/SCTR/LER</td>\n",
       "      <td>20</td>\n",
       "      <td>1.0</td>\n",
       "      <td>012020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>96110</td>\n",
       "      <td>MALBRANCHE</td>\n",
       "      <td>PHILIPPE</td>\n",
       "      <td>Masculin</td>\n",
       "      <td>française</td>\n",
       "      <td>CDI</td>\n",
       "      <td>Annexe 1</td>\n",
       "      <td>Cadres</td>\n",
       "      <td>INGENIEUR CHERCHEUR</td>\n",
       "      <td>RESPONSABLE LIGNE DE PROGRAMME</td>\n",
       "      <td>...</td>\n",
       "      <td>1982-07-01</td>\n",
       "      <td>1982-07-01</td>\n",
       "      <td>NaT</td>\n",
       "      <td>(LITEN)</td>\n",
       "      <td>(LITEN)</td>\n",
       "      <td>(LITEN)</td>\n",
       "      <td>DRT/LITEN///</td>\n",
       "      <td>10</td>\n",
       "      <td>1.0</td>\n",
       "      <td>012020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>97212</td>\n",
       "      <td>MEMPONTEIL</td>\n",
       "      <td>ALAIN</td>\n",
       "      <td>Masculin</td>\n",
       "      <td>française</td>\n",
       "      <td>CDI</td>\n",
       "      <td>Annexe 1</td>\n",
       "      <td>Cadres</td>\n",
       "      <td>INGENIEUR CHERCHEUR</td>\n",
       "      <td>DIPHASIQUE</td>\n",
       "      <td>...</td>\n",
       "      <td>1984-01-23</td>\n",
       "      <td>1984-01-23</td>\n",
       "      <td>NaT</td>\n",
       "      <td>DTBH</td>\n",
       "      <td>SCTR</td>\n",
       "      <td>LER</td>\n",
       "      <td>DRT/LITEN/DTBH/SCTR/LER</td>\n",
       "      <td>10</td>\n",
       "      <td>0.5</td>\n",
       "      <td>012020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>97973</td>\n",
       "      <td>FOURNIER</td>\n",
       "      <td>ADELINE</td>\n",
       "      <td>Féminin</td>\n",
       "      <td>française</td>\n",
       "      <td>CDI</td>\n",
       "      <td>Annexe 2</td>\n",
       "      <td>Tech. rech. ou prod.</td>\n",
       "      <td>RESPONSABLE TECHNIQUE</td>\n",
       "      <td>MICROELECTRONIQUE/TECHNOLOGIE/COMPOSANT</td>\n",
       "      <td>...</td>\n",
       "      <td>1982-07-02</td>\n",
       "      <td>1982-07-02</td>\n",
       "      <td>NaT</td>\n",
       "      <td>DTNM</td>\n",
       "      <td>SCSF</td>\n",
       "      <td>LCH</td>\n",
       "      <td>DRT/LITEN/DTNM/SCSF/LCH</td>\n",
       "      <td>10</td>\n",
       "      <td>1.0</td>\n",
       "      <td>012020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>98251</td>\n",
       "      <td>BRENET</td>\n",
       "      <td>DIDIER</td>\n",
       "      <td>Masculin</td>\n",
       "      <td>française</td>\n",
       "      <td>CDI</td>\n",
       "      <td>Annexe 1</td>\n",
       "      <td>Cadres</td>\n",
       "      <td>INGENIEUR CHERCHEUR</td>\n",
       "      <td>CHEF DE PROJET</td>\n",
       "      <td>...</td>\n",
       "      <td>1980-08-25</td>\n",
       "      <td>1980-08-25</td>\n",
       "      <td>NaT</td>\n",
       "      <td>(LITEN)</td>\n",
       "      <td>DIROPS</td>\n",
       "      <td>CSOP</td>\n",
       "      <td>DRT/LITEN//DIROPS/CSOP</td>\n",
       "      <td>10</td>\n",
       "      <td>1.0</td>\n",
       "      <td>012020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12305</th>\n",
       "      <td>602390</td>\n",
       "      <td>SOURDET</td>\n",
       "      <td>LAURENCE</td>\n",
       "      <td>Féminin</td>\n",
       "      <td>française</td>\n",
       "      <td>CDI</td>\n",
       "      <td>Annexe 1</td>\n",
       "      <td>Cadres</td>\n",
       "      <td>INGENIEUR CHERCHEUR</td>\n",
       "      <td>SURETE DES INSTALLATIONS</td>\n",
       "      <td>...</td>\n",
       "      <td>2005-02-01</td>\n",
       "      <td>2005-02-01</td>\n",
       "      <td>NaT</td>\n",
       "      <td>(LITEN)</td>\n",
       "      <td>DIROPS</td>\n",
       "      <td>CSOP</td>\n",
       "      <td>DRT/LITEN//DIROPS/CSOP</td>\n",
       "      <td>10</td>\n",
       "      <td>1.0</td>\n",
       "      <td>122020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12306</th>\n",
       "      <td>602654</td>\n",
       "      <td>VOARINO</td>\n",
       "      <td>PHILIPPE</td>\n",
       "      <td>Masculin</td>\n",
       "      <td>française</td>\n",
       "      <td>CDI</td>\n",
       "      <td>Annexe 1</td>\n",
       "      <td>Cadres</td>\n",
       "      <td>INGENIEUR CHERCHEUR</td>\n",
       "      <td>DEVELOPPEMENTS DE PROCEDES</td>\n",
       "      <td>...</td>\n",
       "      <td>2012-03-01</td>\n",
       "      <td>2012-03-01</td>\n",
       "      <td>NaT</td>\n",
       "      <td>DTS</td>\n",
       "      <td>SMPV</td>\n",
       "      <td>LMPI</td>\n",
       "      <td>DRT/LITEN/DTS/SMPV/LMPI</td>\n",
       "      <td>10</td>\n",
       "      <td>1.0</td>\n",
       "      <td>122020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12307</th>\n",
       "      <td>602722</td>\n",
       "      <td>DEVILLE</td>\n",
       "      <td>JULIEN</td>\n",
       "      <td>Masculin</td>\n",
       "      <td>française</td>\n",
       "      <td>CDI</td>\n",
       "      <td>Annexe 1</td>\n",
       "      <td>Cadres</td>\n",
       "      <td>INGENIEUR CHERCHEUR</td>\n",
       "      <td>INGENIEUR SECURITE</td>\n",
       "      <td>...</td>\n",
       "      <td>2007-01-03</td>\n",
       "      <td>2007-01-03</td>\n",
       "      <td>NaT</td>\n",
       "      <td>DTS</td>\n",
       "      <td>(DTS)</td>\n",
       "      <td>(DTS)</td>\n",
       "      <td>DRT/LITEN/DTS//</td>\n",
       "      <td>10</td>\n",
       "      <td>1.0</td>\n",
       "      <td>122020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12308</th>\n",
       "      <td>604233</td>\n",
       "      <td>REYNAUD</td>\n",
       "      <td>DENIS</td>\n",
       "      <td>Masculin</td>\n",
       "      <td>française</td>\n",
       "      <td>CDI</td>\n",
       "      <td>Annexe 2</td>\n",
       "      <td>Tech. rech. ou prod.</td>\n",
       "      <td>TECHNICIEN SUPERIEUR</td>\n",
       "      <td>ROBOTIQUE ET AUTOMATISME</td>\n",
       "      <td>...</td>\n",
       "      <td>2008-08-25</td>\n",
       "      <td>2008-08-25</td>\n",
       "      <td>NaT</td>\n",
       "      <td>DTBH</td>\n",
       "      <td>STHB</td>\n",
       "      <td>LTH</td>\n",
       "      <td>DRT/LITEN/DTBH/STHB/LTH</td>\n",
       "      <td>10</td>\n",
       "      <td>1.0</td>\n",
       "      <td>122020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12309</th>\n",
       "      <td>606998</td>\n",
       "      <td>HENAULT</td>\n",
       "      <td>KILIAN</td>\n",
       "      <td>Masculin</td>\n",
       "      <td>française</td>\n",
       "      <td>CDI</td>\n",
       "      <td>Annexe 1</td>\n",
       "      <td>Cadres</td>\n",
       "      <td>INGENIEUR CHERCHEUR</td>\n",
       "      <td>TECHNOLOGIES MECANIQUES</td>\n",
       "      <td>...</td>\n",
       "      <td>2020-09-01</td>\n",
       "      <td>2020-09-01</td>\n",
       "      <td>NaT</td>\n",
       "      <td>DTBH</td>\n",
       "      <td>STHB</td>\n",
       "      <td>LTH</td>\n",
       "      <td>DRT/LITEN/DTBH/STHB/LTH</td>\n",
       "      <td>10</td>\n",
       "      <td>1.0</td>\n",
       "      <td>122020</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>12310 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Matricule         Nom    Prénom Sexe(lib) Nationalité (lib)  \\\n",
       "0          67942     CLEMENT   PATRICE  Masculin         française   \n",
       "1          96110  MALBRANCHE  PHILIPPE  Masculin         française   \n",
       "2          97212  MEMPONTEIL     ALAIN  Masculin         française   \n",
       "3          97973    FOURNIER   ADELINE   Féminin         française   \n",
       "4          98251      BRENET    DIDIER  Masculin         française   \n",
       "...          ...         ...       ...       ...               ...   \n",
       "12305     602390     SOURDET  LAURENCE   Féminin         française   \n",
       "12306     602654     VOARINO  PHILIPPE  Masculin         française   \n",
       "12307     602722     DEVILLE    JULIEN  Masculin         française   \n",
       "12308     604233     REYNAUD     DENIS  Masculin         française   \n",
       "12309     606998     HENAULT    KILIAN  Masculin         française   \n",
       "\n",
       "      Catégorie de salarié (lib) Statut de salarié (lib)  \\\n",
       "0             Conseiller Scient.    Conseiller Scient.NR   \n",
       "1                            CDI                Annexe 1   \n",
       "2                            CDI                Annexe 1   \n",
       "3                            CDI                Annexe 2   \n",
       "4                            CDI                Annexe 1   \n",
       "...                          ...                     ...   \n",
       "12305                        CDI                Annexe 1   \n",
       "12306                        CDI                Annexe 1   \n",
       "12307                        CDI                Annexe 1   \n",
       "12308                        CDI                Annexe 2   \n",
       "12309                        CDI                Annexe 1   \n",
       "\n",
       "      Filière classement (lib) Qualification classement (lib)  \\\n",
       "0                          NaN        CONSEILLER SCIENTIFIQUE   \n",
       "1                       Cadres            INGENIEUR CHERCHEUR   \n",
       "2                       Cadres            INGENIEUR CHERCHEUR   \n",
       "3         Tech. rech. ou prod.          RESPONSABLE TECHNIQUE   \n",
       "4                       Cadres            INGENIEUR CHERCHEUR   \n",
       "...                        ...                            ...   \n",
       "12305                   Cadres            INGENIEUR CHERCHEUR   \n",
       "12306                   Cadres            INGENIEUR CHERCHEUR   \n",
       "12307                   Cadres            INGENIEUR CHERCHEUR   \n",
       "12308     Tech. rech. ou prod.           TECHNICIEN SUPERIEUR   \n",
       "12309                   Cadres            INGENIEUR CHERCHEUR   \n",
       "\n",
       "                        Spécialité poste (lib)  ... Date début contrat  \\\n",
       "0                                          NaN  ...         2019-08-01   \n",
       "1               RESPONSABLE LIGNE DE PROGRAMME  ...         1982-07-01   \n",
       "2                                   DIPHASIQUE  ...         1984-01-23   \n",
       "3      MICROELECTRONIQUE/TECHNOLOGIE/COMPOSANT  ...         1982-07-02   \n",
       "4                               CHEF DE PROJET  ...         1980-08-25   \n",
       "...                                        ...  ...                ...   \n",
       "12305                 SURETE DES INSTALLATIONS  ...         2005-02-01   \n",
       "12306               DEVELOPPEMENTS DE PROCEDES  ...         2012-03-01   \n",
       "12307                       INGENIEUR SECURITE  ...         2007-01-03   \n",
       "12308                 ROBOTIQUE ET AUTOMATISME  ...         2008-08-25   \n",
       "12309                  TECHNOLOGIES MECANIQUES  ...         2020-09-01   \n",
       "\n",
       "      Date dernière entrée Date de fin de contrat Dpt/DOB (lib court)  \\\n",
       "0               2012-08-01             2020-07-31                DTBH   \n",
       "1               1982-07-01                    NaT             (LITEN)   \n",
       "2               1984-01-23                    NaT                DTBH   \n",
       "3               1982-07-02                    NaT                DTNM   \n",
       "4               1980-08-25                    NaT             (LITEN)   \n",
       "...                    ...                    ...                 ...   \n",
       "12305           2005-02-01                    NaT             (LITEN)   \n",
       "12306           2012-03-01                    NaT                 DTS   \n",
       "12307           2007-01-03                    NaT                 DTS   \n",
       "12308           2008-08-25                    NaT                DTBH   \n",
       "12309           2020-09-01                    NaT                DTBH   \n",
       "\n",
       "      Service (lib court) Laboratoire (lib court)   Laboratoire (lib long)  \\\n",
       "0                    SCTR                     LER  DRT/LITEN/DTBH/SCTR/LER   \n",
       "1                 (LITEN)                 (LITEN)             DRT/LITEN///   \n",
       "2                    SCTR                     LER  DRT/LITEN/DTBH/SCTR/LER   \n",
       "3                    SCSF                     LCH  DRT/LITEN/DTNM/SCSF/LCH   \n",
       "4                  DIROPS                    CSOP   DRT/LITEN//DIROPS/CSOP   \n",
       "...                   ...                     ...                      ...   \n",
       "12305              DIROPS                    CSOP   DRT/LITEN//DIROPS/CSOP   \n",
       "12306                SMPV                    LMPI  DRT/LITEN/DTS/SMPV/LMPI   \n",
       "12307               (DTS)                   (DTS)          DRT/LITEN/DTS//   \n",
       "12308                STHB                     LTH  DRT/LITEN/DTBH/STHB/LTH   \n",
       "12309                STHB                     LTH  DRT/LITEN/DTBH/STHB/LTH   \n",
       "\n",
       "      Nature de dépenses   TA  mmaaaa  \n",
       "0                     20  1.0  012020  \n",
       "1                     10  1.0  012020  \n",
       "2                     10  0.5  012020  \n",
       "3                     10  1.0  012020  \n",
       "4                     10  1.0  012020  \n",
       "...                  ...  ...     ...  \n",
       "12305                 10  1.0  122020  \n",
       "12306                 10  1.0  122020  \n",
       "12307                 10  1.0  122020  \n",
       "12308                 10  1.0  122020  \n",
       "12309                 10  1.0  122020  \n",
       "\n",
       "[12310 rows x 23 columns]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_de_df_par_annee[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "84f5ac7d-608a-45a3-84e4-55c83447f48c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1025.8333333333333"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "d8c8fee8-e511-400a-a838-d38bade2c3d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = list_de_df_par_annee[2]\n",
    "\n",
    "dg_mmaaa = pd.DataFrame.from_dict({x[0]:[x[1]['mmaaaa'].tolist()] for x in df.groupby(['Matricule'])}).T\n",
    "dg_mmaaa.index.name = 'Matricule'\n",
    "dg_mmaaa.columns = ['list of mmaaaa']\n",
    "dg_mmaaa.reset_index(inplace = True)\n",
    "\n",
    "dg_depart = pd.DataFrame.from_dict({x[0]:[x[1]['Dpt/DOB (lib court)'].tolist()] for x in df.groupby(['Matricule'])}).T\n",
    "dg_depart.index.name = 'Matricule'\n",
    "dg_depart.columns = ['list of Dpt/DOB (lib court)']\n",
    "dg_depart.reset_index(inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "dbb407bb-0f09-4b97-b994-5ab072287324",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = list_de_df_par_annee[2].drop_duplicates(subset='Matricule')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "f90ab700-f6dc-4874-affb-ad6fdc717554",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.merge(df, dg_mmaaa, how = 'left', left_on = ['Matricule'], right_on = ['Matricule'])\n",
    "df = pd.merge(df, dg_depart, how = 'left', left_on = ['Matricule'], right_on = ['Matricule'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "39e06f26-2709-4ed6-9874-f6a40f4e40dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Matricule</th>\n",
       "      <th>Nom</th>\n",
       "      <th>Prénom</th>\n",
       "      <th>list of mmaaaa</th>\n",
       "      <th>list of Dpt/DOB (lib court)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>67942</td>\n",
       "      <td>CLEMENT</td>\n",
       "      <td>PATRICE</td>\n",
       "      <td>[012021, 022021, 032021, 042021, 052021, 06202...</td>\n",
       "      <td>[DTCH, DTCH, DTCH, DTCH, DTCH, DTCH, DTCH, DTC...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>96110</td>\n",
       "      <td>MALBRANCHE</td>\n",
       "      <td>PHILIPPE</td>\n",
       "      <td>[012021, 022021, 032021, 042021, 052021, 06202...</td>\n",
       "      <td>[(LITEN), (LITEN), (LITEN), (LITEN), (LITEN), ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>97973</td>\n",
       "      <td>FOURNIER</td>\n",
       "      <td>ADELINE</td>\n",
       "      <td>[012021, 022021, 032021]</td>\n",
       "      <td>[DTNM, DTNM, DTNM]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>98284</td>\n",
       "      <td>BABLET</td>\n",
       "      <td>JACQUELINE</td>\n",
       "      <td>[012021, 022021, 032021, 042021, 052021, 06202...</td>\n",
       "      <td>[DTNM, DTNM, DTNM, DTNM, DTNM, DTNM, DTNM, DTN...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>98350</td>\n",
       "      <td>MILLON-FREMILLON</td>\n",
       "      <td>BRUNO</td>\n",
       "      <td>[012021, 022021, 032021, 042021, 052021, 06202...</td>\n",
       "      <td>[DTCH, DTCH, DTCH, DTCH, DTCH, DTCH, DTCH, DTC...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1233</th>\n",
       "      <td>268325</td>\n",
       "      <td>BOUKERCHE</td>\n",
       "      <td>GHEZLENE</td>\n",
       "      <td>[092021]</td>\n",
       "      <td>[(LITEN)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1234</th>\n",
       "      <td>268329</td>\n",
       "      <td>CHARPANTIER</td>\n",
       "      <td>BAPTISTE</td>\n",
       "      <td>[092021]</td>\n",
       "      <td>[DTNM]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1235</th>\n",
       "      <td>268332</td>\n",
       "      <td>DAUTAIN</td>\n",
       "      <td>NICOLAS</td>\n",
       "      <td>[092021]</td>\n",
       "      <td>[DEHT]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1236</th>\n",
       "      <td>268425</td>\n",
       "      <td>LANGLET</td>\n",
       "      <td>PIERRE-JEAN</td>\n",
       "      <td>[092021]</td>\n",
       "      <td>[DTNM]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1237</th>\n",
       "      <td>268525</td>\n",
       "      <td>ROSTOLAN</td>\n",
       "      <td>MAXIME</td>\n",
       "      <td>[092021]</td>\n",
       "      <td>[DTS]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1238 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Matricule               Nom       Prénom  \\\n",
       "0         67942           CLEMENT      PATRICE   \n",
       "1         96110        MALBRANCHE     PHILIPPE   \n",
       "2         97973          FOURNIER      ADELINE   \n",
       "3         98284            BABLET   JACQUELINE   \n",
       "4         98350  MILLON-FREMILLON        BRUNO   \n",
       "...         ...               ...          ...   \n",
       "1233     268325         BOUKERCHE     GHEZLENE   \n",
       "1234     268329       CHARPANTIER     BAPTISTE   \n",
       "1235     268332           DAUTAIN      NICOLAS   \n",
       "1236     268425           LANGLET  PIERRE-JEAN   \n",
       "1237     268525          ROSTOLAN       MAXIME   \n",
       "\n",
       "                                         list of mmaaaa  \\\n",
       "0     [012021, 022021, 032021, 042021, 052021, 06202...   \n",
       "1     [012021, 022021, 032021, 042021, 052021, 06202...   \n",
       "2                              [012021, 022021, 032021]   \n",
       "3     [012021, 022021, 032021, 042021, 052021, 06202...   \n",
       "4     [012021, 022021, 032021, 042021, 052021, 06202...   \n",
       "...                                                 ...   \n",
       "1233                                           [092021]   \n",
       "1234                                           [092021]   \n",
       "1235                                           [092021]   \n",
       "1236                                           [092021]   \n",
       "1237                                           [092021]   \n",
       "\n",
       "                            list of Dpt/DOB (lib court)  \n",
       "0     [DTCH, DTCH, DTCH, DTCH, DTCH, DTCH, DTCH, DTC...  \n",
       "1     [(LITEN), (LITEN), (LITEN), (LITEN), (LITEN), ...  \n",
       "2                                    [DTNM, DTNM, DTNM]  \n",
       "3     [DTNM, DTNM, DTNM, DTNM, DTNM, DTNM, DTNM, DTN...  \n",
       "4     [DTCH, DTCH, DTCH, DTCH, DTCH, DTCH, DTCH, DTC...  \n",
       "...                                                 ...  \n",
       "1233                                          [(LITEN)]  \n",
       "1234                                             [DTNM]  \n",
       "1235                                             [DEHT]  \n",
       "1236                                             [DTNM]  \n",
       "1237                                              [DTS]  \n",
       "\n",
       "[1238 rows x 5 columns]"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[['Matricule','Nom','Prénom','list of mmaaaa','list of Dpt/DOB (lib court)']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "ce9b213b-3f01-48bb-ba93-ae3c979976ce",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "list_authors_LITEN = ['Aixala L',\n",
    " 'Amalbert V',\n",
    " 'Amari S',\n",
    " 'Amestoy B',\n",
    " 'Anxionnaz-Minvielle Z',\n",
    " 'Arrive C',\n",
    " 'Assoa YB',\n",
    " 'Azais P',\n",
    " 'Baffie T',\n",
    " 'Bancillon J',\n",
    " 'Barchasz C',\n",
    " 'Bazin P',\n",
    " 'Bellouard Q',\n",
    " 'Benayad A',\n",
    " 'Bengaouer A',\n",
    " 'Benwadih M',\n",
    " 'Beranger B',\n",
    " 'Besanger Y',\n",
    " 'Beust C',\n",
    " 'Blaise A',\n",
    " 'Blanc L',\n",
    " 'Blondel Q',\n",
    " 'Bohnke M',\n",
    " 'Bolloli M',\n",
    " 'Boudehenn F',\n",
    " 'Boujjat H',\n",
    " 'Boulineau A',\n",
    " 'Bourasseau C',\n",
    " 'Bourdon D',\n",
    " 'Briottet L',\n",
    " 'Bruch A',\n",
    " 'Brunot A',\n",
    " 'Buzon D',\n",
    " 'Cadiou V',\n",
    " 'Calapez J',\n",
    " 'Carella A',\n",
    " 'Cariou R',\n",
    " 'Cayre S',\n",
    " 'Cayron C',\n",
    " 'Celle C',\n",
    " 'Chabuel F',\n",
    " 'Chaise A',\n",
    " 'Champon I',\n",
    " 'Chandesris M',\n",
    " 'Chappaz A',\n",
    " 'Charbonneau M',\n",
    " 'Chariere R',\n",
    " 'Chatroux D',\n",
    " 'Chavillon B',\n",
    " 'Choubrac L',\n",
    " 'Chu I',\n",
    " 'Clerjon A',\n",
    " 'Colin J-F',\n",
    " 'Cor E',\n",
    " 'Coron E',\n",
    " 'Cren J',\n",
    " 'Cwicklinski G',\n",
    " 'Dahou T',\n",
    " 'Dally P',\n",
    " 'Dalmasso M',\n",
    " 'De Vincent PP',\n",
    " 'De Vito E',\n",
    " 'Defoort F',\n",
    " 'Delahaye T',\n",
    " 'Delette G',\n",
    " 'Delhommais M',\n",
    " 'Dellea O',\n",
    " 'Dijon J',\n",
    " 'Dini Y',\n",
    " 'Douard S',\n",
    " 'Ducros F',\n",
    " 'Ducros J-B',\n",
    " 'Dumas C',\n",
    " 'Dupont C',\n",
    " 'Ecrabey J',\n",
    " 'Emieux F',\n",
    " 'Escribano S',\n",
    " 'Euvrard J',\n",
    " 'Ez-Zaki H',\n",
    " 'Fanget O',\n",
    " 'Faucherand P',\n",
    " 'Faure G',\n",
    " 'Favre W',\n",
    " 'Flament C',\n",
    " 'Fliegans J',\n",
    " 'Fourmigue J-F',\n",
    " 'Gaillard G',\n",
    " 'Gallaire D',\n",
    " 'Garandet J-P',\n",
    " 'Garcia P',\n",
    " 'Garnier L',\n",
    " 'Gauthier GH',\n",
    " 'Gebel G',\n",
    " 'Geni S S',\n",
    " 'Genies S',\n",
    " 'Gentzbittel J-M',\n",
    " 'Gerard M',\n",
    " 'Golanski L',\n",
    " 'Gonzalez B',\n",
    " 'Grateau M',\n",
    " 'Grenet L',\n",
    " 'Guetaz L',\n",
    " 'Gueye M',\n",
    " 'Gueye MN',\n",
    " 'Gutel E',\n",
    " 'Gutel T',\n",
    " 'Haddad C',\n",
    " 'Haon C',\n",
    " 'Hoang T-T',\n",
    " 'Hugonnet B',\n",
    " 'Indris S',\n",
    " 'Jacome A',\n",
    " 'Jany C',\n",
    " 'Josel H-P',\n",
    " 'Jullian G',\n",
    " 'Karuppiah S',\n",
    " 'Keller C',\n",
    " 'Kim GT',\n",
    " 'Latour A',\n",
    " 'Laucournet R',\n",
    " 'Laurencin J',\n",
    " 'Le Baron E',\n",
    " 'Le Comte A',\n",
    " 'Le Cras F',\n",
    " 'Le M-T',\n",
    " 'Lee J',\n",
    " 'Lemaitre N',\n",
    " 'Levrard D',\n",
    " 'Leys C',\n",
    " 'Lorin G',\n",
    " 'Lory P-F',\n",
    " 'Mainguet J-F',\n",
    " 'Mansour C',\n",
    " 'Marquez JA',\n",
    " 'Martin A',\n",
    " 'Martin J-F',\n",
    " 'Martinent A',\n",
    " 'Martinez N',\n",
    " 'Mastrippolito F',\n",
    " 'Mathieu B',\n",
    " 'Mayousse E',\n",
    " 'Medjoubi K',\n",
    " 'Mercier S',\n",
    " 'Mercier-Guyon B',\n",
    " 'Michaud T',\n",
    " 'Micoud F',\n",
    " 'Miller H',\n",
    " 'Mingo N',\n",
    " 'Monaco F',\n",
    " 'Monnier E',\n",
    " 'Morales-Ugarte JE',\n",
    " 'Morel B',\n",
    " 'Morin A',\n",
    " 'Mougin J',\n",
    " 'Moussaoui H',\n",
    " 'Mugnier H',\n",
    " 'Nadal A',\n",
    " 'Naser H',\n",
    " 'Navone C',\n",
    " 'Nguyen T-L',\n",
    " 'Nobre SDS',\n",
    " 'Nobre SS',\n",
    " 'Nunes Domschke T',\n",
    " 'Opprecht M',\n",
    " 'Panzone C',\n",
    " 'Paulus C',\n",
    " 'Peralta D',\n",
    " 'Perdu F',\n",
    " 'Pereira A',\n",
    " 'Pescheux A-C',\n",
    " 'Peyrot M',\n",
    " 'Peyrouzet F',\n",
    " 'Phan HT',\n",
    " 'Poirot-Crouvezier J-P',\n",
    " 'Porcher W',\n",
    " 'Pouvreau J',\n",
    " 'Pras M',\n",
    " 'Profatilova I',\n",
    " 'Raccurt O',\n",
    " 'Rado C',\n",
    " 'Randrianarizafy B',\n",
    " 'Ravel S',\n",
    " 'Revaux A',\n",
    " 'Reynier Y',\n",
    " 'Rigal E',\n",
    " 'Robba A',\n",
    " 'Rodat S',\n",
    " 'Rodosik S',\n",
    " 'Romanjek K',\n",
    " 'Rosini S',\n",
    " 'Rostaing C',\n",
    " 'Roux F',\n",
    " 'Roux G',\n",
    " 'Ruby A',\n",
    " 'Saavedra Rios CDM',\n",
    " 'Saint-Antonin F',\n",
    " 'Sandroni M',\n",
    " 'Savelli G',\n",
    " 'Schott P',\n",
    " 'Schultheiss A',\n",
    " 'Sharma H',\n",
    " 'Simonato J-P',\n",
    " 'Simonin L',\n",
    " 'Singh V',\n",
    " 'Soulas R',\n",
    " 'Soulier M',\n",
    " 'Tauveron N',\n",
    " 'Thiery S',\n",
    " 'Tomasi D',\n",
    " 'Tosoni O',\n",
    " 'Tran Q-T',\n",
    " 'Tran QT',\n",
    " 'Tran TQ',\n",
    " 'Valin S',\n",
    " 'Vallee M',\n",
    " 'Van A-LB',\n",
    " 'Van Roekeghem A',\n",
    " 'Vauche L',\n",
    " 'Veinberg-Vidal E',\n",
    " 'Verilhac J-M',\n",
    " 'Vermeersch B',\n",
    " 'Vincens C',\n",
    " 'Vincent D',\n",
    " 'Vincent R',\n",
    " 'Vinet B',\n",
    " 'Voeltzel N',\n",
    " 'Walus S',\n",
    " 'Wirtz M',\n",
    " 'Yuki Junior GM',\n",
    " 'Yvenou E',\n",
    " 'Zinkevich T']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fe58e00b-9df3-4a99-a1f1-a648d937d58d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard library import\n",
    "import string\n",
    "import random\n",
    "\n",
    "# 3rd party import\n",
    "import openpyxl\n",
    "from openpyxl import Workbook,load_workbook\n",
    "from openpyxl.comments import Comment\n",
    "from openpyxl.utils.cell import get_column_letter\n",
    "from openpyxl.worksheet.datavalidation import DataValidation\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def highlight_homonyms(x):\n",
    "    if x in homonyms:\n",
    "        return 'background-color: '+ color_homonym\n",
    "    return ''\n",
    "\n",
    "def builds_random_df():\n",
    "    '''Build the NrowsxNcols dataframe df containing random strings of type LD\n",
    "    where L in a capital letter and D digit equal to 0 or 1.\n",
    "    '''\n",
    "    \n",
    "    name =[x+str(y) for x in string.ascii_uppercase for y in [0,1]][0:Ncols]\n",
    "\n",
    "    A = np.reshape(random.sample(name*Nrows,Nrows*Ncols),(Nrows,Ncols))\n",
    "    \n",
    "    df = pd.DataFrame(A, columns=['COL'+str(i) for i in range(Ncols)])\n",
    "    \n",
    "    return df\n",
    "    \n",
    "    \n",
    "Ncols = 10\n",
    "Nrows = 500\n",
    "homonyms = ['B1','C0']         # List of homonyms to be detected\n",
    "color_homonym = '#FF0AB0'      # https://www.w3schools.com/colors/colors_picker.asp\n",
    "col_to_check_homonym = 'COL2'  # must be COL<i> with i = 0,1,...,Ncols-1\n",
    "sheet_name = 'Sheet1'\n",
    "\n",
    "\n",
    "df = builds_random_df()      # Builds random dataframe\n",
    "\n",
    "# Find homonyms and highlight the corresponding cells\n",
    "df.style.applymap(highlight_homonyms,\n",
    "                  subset= [col_to_check_homonym]).to_excel(r'c:\\Temp\\highlight.xlsx')\n",
    "\n",
    "# Adds comments to the highlighted cells\n",
    "comment = Comment(\"Homonymy detected \", \"Author\")\n",
    "comment.width = 300\n",
    "comment.height = 50\n",
    "\n",
    "wb = load_workbook(r'c:\\Temp\\highlight.xlsx', data_only = True)\n",
    "ws = wb.active\n",
    "sh = wb[sheet_name]\n",
    "\n",
    "col_names = list(df.columns)\n",
    "excel_col_name = get_column_letter(col_names.index(col_to_check_homonym) + 2) # Beware the +2 \n",
    "\n",
    "for idx in range(1,len(df)+1):  # Sweep the columns in which we are looking for homonyms\n",
    "    excel_cell_id = excel_col_name+str(idx+1)\n",
    "    color_in_hex = sh[excel_cell_id].fill.start_color.index # Cell color in hex\n",
    "    if color_in_hex[2:] == color_homonym[1:] : \n",
    "        ws[excel_cell_id].comment = comment\n",
    "        \n",
    "validation_list = [\"C0\",\"D1\",\"B2\"]    # list of valid items\n",
    "validation_list = '\"'+','.join(validation_list)+'\"' # tobe compatible with openpyxl formatting\n",
    "\n",
    "data_val = DataValidation(type=\"list\",formula1=validation_list, allow_blank=True)\n",
    "ws.add_data_validation(data_val)\n",
    "\n",
    "for index_row in range(1,20):\n",
    "    data_val.add(ws[\"B\"+str(index_row)])\n",
    "\n",
    "validation_list2 = [\"C0\",\"D1\",\"aergzergzerg\"]    # list of valid items\n",
    "validation_list2 = '\"'+','.join(validation_list2)+'\"' # tobe compatible with openpyxl formatting\n",
    "\n",
    "data_val2 = DataValidation(type=\"list\",formula1=validation_list2, allow_blank=True)\n",
    "ws.add_data_validation(data_val2)\n",
    "\n",
    "for index_row in range(1,20):\n",
    "    data_val2.add(ws[\"B\"+str(index_row)])\n",
    "\n",
    "wb.save(r'c:\\Temp\\highlight.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a6021d4b-98c8-4ec4-bd55-efe9ccea07e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openpyxl import Workbook\n",
    "from openpyxl.worksheet.datavalidation import DataValidation\n",
    "\n",
    "wb = Workbook()\n",
    "\n",
    "ws = wb.create_sheet('New Sheet')\n",
    "\n",
    "for number in range(1,100): #Generates 99 \"ip\" address in the Column A;\n",
    "    ws['A{}'.format(number)].value= \"192.168.1.{}\".format(number)\n",
    "\n",
    "data_val = DataValidation(type=\"list\",formula1='=$A:$A') #You can change =$A:$A with a smaller range like =A1:A9\n",
    "ws.add_data_validation(data_val)\n",
    "\n",
    "data_val.add(ws[\"B1\"]) #If you go to the cell B1 you will find a drop down list with all the values from the column A\n",
    "\n",
    "wb.save(r'c:\\Temp\\Test.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5a774b6-c9c7-4922-a9ca-272ec5d7f68b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
