{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f8dd7720-9534-4845-82a1-1c47db6dc78e",
   "metadata": {},
   "source": [
    "# User environment settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "503121fd-59dd-4908-8d3a-943b79bad4de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Virtual environment:  False\n",
      "Operating system:     Windows\n",
      "User:                 C:\\Users\\ld259969\n",
      "\n",
      "Corpuses folder: C:/Users/ld259969/Documents/PyVenv/BiblioMeterDraft/Liten_Corpuses\n"
     ]
    }
   ],
   "source": [
    "# Standard library imports\n",
    "import platform\n",
    "import os\n",
    "from IPython.display import clear_output\n",
    "from pathlib import Path\n",
    "\n",
    "# Local imports\n",
    "import BiblioAnalysis_Utils as bau\n",
    "\n",
    "clear_output(wait=True)\n",
    "\n",
    "# Set the venv use status\n",
    "venv = False\n",
    "print('Virtual environment: ', venv)\n",
    "\n",
    "# Get the information of current operating system\n",
    "os_name = platform.uname().system\n",
    "print('Operating system:    ', os_name)\n",
    "if os_name=='Darwin':bau.add_site_packages_path(venv)\n",
    "\n",
    "# User identification\n",
    "user_root = Path.home()\n",
    "user_id =  str(user_root)[str(user_root).rfind('/')+1:]\n",
    "print('User:                ', user_id)\n",
    "expert =  False\n",
    "\n",
    "# Select the corpuses folder\n",
    "corpuses_folder = bau.select_folder_gui(user_root,'Select the corpuses folder')\n",
    "print('\\nCorpuses folder:', corpuses_folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c23821b-f980-43dd-ba1e-4f065483411c",
   "metadata": {},
   "source": [
    "## I - Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "aefd9c59-8e3b-4ab2-9ceb-34c227f9ff2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please select the corpus via the tk window\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Corpus file type (scopus, wos - default: \"wos\")?  wos\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Specific-paths set for user:  C:\\Users\\ld259969\n",
      "Project folder:               C:\\Users\\ld259969\\Documents\\PyVenv\\BiblioMeterDraft\\Liten_Corpuses\\2021_wos\n",
      "Corpus year:                  2021\n",
      "Corpus status:                Corpuses\n",
      "Project name:                 2021_wos/\n",
      "Corpus file type:             wos\n"
     ]
    }
   ],
   "source": [
    "# Standard library imports\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "# Local imports\n",
    "import BiblioAnalysis_Utils as bau\n",
    "\n",
    "## Selection of corpus file\n",
    "corpusfiles_list = os.listdir(corpuses_folder)\n",
    "corpusfiles_list.sort()\n",
    "print('Please select the corpus via the tk window')\n",
    "myprojectname = bau.Select_multi_items(corpusfiles_list,'single')[0]+'/'\n",
    "project_folder = corpuses_folder /Path(myprojectname)\n",
    "database_type = input('Corpus file type (scopus, wos - default: \"wos\")? ')\n",
    "if database_type =='': database_type = 'wos' \n",
    "\n",
    "rep_utils =''\n",
    "if database_type =='scopus':\n",
    "     # Get the folder for the general files\n",
    "     # and specific files for scopus type database in this folder\n",
    "    if os_name=='Darwin':\n",
    "        rep_utils = os.path.abspath('BiblioAnalysis_RefFiles')        \n",
    "    else:\n",
    "        rep_utils = bau.select_folder_gui(user_root,'Select the folder specific files for scopus')        \n",
    "    scopus_cat_codes = bau.SCOPUS_CAT_CODES\n",
    "    scopus_journals_issn_cat = bau.SCOPUS_JOURNALS_ISSN_CAT\n",
    "    print('Folder of the specific files for scopus:', rep_utils)       \n",
    "    \n",
    "## Setting the  graph main heading\n",
    "digits_list = list(filter(str.isdigit, myprojectname))\n",
    "corpus_year = ''\n",
    "for i in range(len(digits_list)):corpus_year = corpus_year + digits_list[i]\n",
    "init = str(corpuses_folder).rfind(\"_\")+1\n",
    "corpus_state = str(corpuses_folder)[init:]\n",
    "main_heading = corpus_year + ' Corpus: ' + corpus_state\n",
    "\n",
    "## Printing useful information\n",
    "print('\\nSpecific-paths set for user: ', user_id)\n",
    "print('Project folder:              ', project_folder)\n",
    "print('Corpus year:                 ', corpus_year)\n",
    "print('Corpus status:               ', corpus_state)\n",
    "print('Project name:                ', myprojectname)\n",
    "print('Corpus file type:            ', database_type)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78807082-639e-4810-b8ea-0e4bae34d568",
   "metadata": {},
   "source": [
    "## II Data Parsing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e6e79d5c-bbe5-4aa2-9b79-b6049f58bad1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Parsing available (y/n)?  n\n",
      "Secondary institutions to be parsed (y/n)?  y\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsing processed on full corpus\n",
      "\n",
      "\n",
      "Success rates\n",
      "    AK: 69.18%\n",
      "    IK: 77.36%\n",
      "    TK: 100.00%\n",
      "    Address: 100.00%\n",
      "    Country: 100.00%\n",
      "    Institution: 100.00%\n",
      "    authors_inst: 100.00%\n",
      "    Subject: 100.00%\n",
      "    Sub_subject: 100.00%\n",
      "\n",
      "\n",
      "Corpus parsing saved in folder:\n",
      " C:\\Users\\ld259969\\Documents\\PyVenv\\BiblioMeterDraft\\Liten_Corpuses\\2021_wos\\parsing\n",
      "\n",
      "Number of articles in the corpus :  159\n"
     ]
    }
   ],
   "source": [
    "# Standard libraries import\n",
    "import os\n",
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "# Local imports\n",
    "import BiblioAnalysis_Utils as bau\n",
    "\n",
    "## Building the names of the useful folders\n",
    "\n",
    "    # Folder containing the wos or scopus file to process\n",
    "in_dir_parsing = project_folder / Path(bau.FOLDER_NAMES['rawdata'])\n",
    "\n",
    "    # Folder containing the output files of the data parsing \n",
    "out_dir_parsing = project_folder / Path(bau.FOLDER_NAMES['parsing'])\n",
    "if not os.path.exists(out_dir_parsing):\n",
    "    os.mkdir(out_dir_parsing)\n",
    "\n",
    "## Running function biblio_parser\n",
    "parser_done = input(\"Parsing available (y/n)? \")\n",
    "if parser_done == \"n\":\n",
    "     # Setting the specific affiliations filter (default = None)\n",
    "    second_inst = input(\"Secondary institutions to be parsed (y/n)? \")\n",
    "    if second_inst=='y' : \n",
    "        inst_filter_dic= {'secondary_inst': ['LITEN','INES'],\n",
    "                          'country': 'France'} \n",
    "    else:\n",
    "        inst_filter_dic = None\n",
    "    bau.biblio_parser(in_dir_parsing, out_dir_parsing, database_type, expert, rep_utils, inst_filter_dic) \n",
    "    with open(Path(out_dir_parsing) / Path('failed.json'), 'r') as failed_json:\n",
    "            data_failed=failed_json.read()\n",
    "    dic_failed = json.loads(data_failed)\n",
    "    articles_number = dic_failed[\"number of article\"]\n",
    "    print(\"Parsing processed on full corpus\")\n",
    "    print(\"\\n\\nSuccess rates\")\n",
    "    del dic_failed['number of article']\n",
    "    for item, value in dic_failed.items():\n",
    "        print(f'    {item}: {value[\"success (%)\"]:.2f}%')\n",
    "else:\n",
    "    parser_filt = input(\"Parsing available without rawdata -from filtering- (y/n)? \")\n",
    "    if parser_filt == \"n\":        \n",
    "        with open(Path(out_dir_parsing) / Path('failed.json'), 'r') as failed_json:\n",
    "            data_failed=failed_json.read()\n",
    "        dic_failed = json.loads(data_failed)\n",
    "        articles_number = dic_failed[\"number of article\"]\n",
    "        #clear_output(wait=True)\n",
    "        print(\"Parsing available from full corpus\")\n",
    "        print(\"\\n\\nSuccess rates\")\n",
    "        del dic_failed['number of article']\n",
    "        for item, value in dic_failed.items():\n",
    "            print(f'    {item}: {value[\"success (%)\"]:.2f}%')\n",
    "    else:\n",
    "        #clear_output(wait=True)\n",
    "        print(\"Parsing available from filtered corpus without rawdata\")\n",
    "        file = project_folder /Path('parsing/' + 'articles.dat')\n",
    "        with open(file) as f:\n",
    "            lines = f.readlines()\n",
    "        articles_number = len(lines)\n",
    "\n",
    "print(\"\\n\\nCorpus parsing saved in folder:\\n\", str(out_dir_parsing))\n",
    "print('\\nNumber of articles in the corpus : ', articles_number)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a69645e-aebe-42c3-8b63-f27910b9fa92",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "BiblioMeter_Utils",
   "language": "python",
   "name": "bibliometer_utils"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
